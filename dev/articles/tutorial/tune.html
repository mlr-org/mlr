<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tuning Hyperparameters • mlr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/journal/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/all.min.css" integrity="sha256-PbSmjxuVAzJ6FPvNYsrXygfGhNJYyZ2GktDbkMBqQZg=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/v4-shims.min.css" integrity="sha256-A6jcAdwFD48VMjlI3GDxUd+eCQa7/KWy6G9oe/ovaPA=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<link href="../../extra.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><!-- docsearch --><script src="../../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Tuning Hyperparameters">
<meta property="og:description" content="mlr">
<meta property="og:image" content="https://mlr.mlr-org.com/logo.png">
<meta name="twitter:card" content="summary">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a href="https://mlr-org.com"><img src="https://raw.githubusercontent.com/mlr-org/mlr3/master/man/figures/logo.png" id="hexlogo" alt="mlr-org"></a>
        <a class="navbar-brand" href="../../index.html">mlr <small>v2.17.1.9006</small></a>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Task</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learner.html">Learner</a>
    </li>
    <li>
      <a href="../../articles/tutorial/train.html">Train</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmarking</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/usecase_regression.html">Use case - Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/configureMlr.html">mlr Configuration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    </li>
    <li>
      <a href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/handling_of_spatial_data.html">Spatial Data</a>
    </li>
    <li>
      <a href="../../articles/tutorial/functional_data.html">Functional Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extending
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/create_learner.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_measure.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_imputation.html">Create Custom Imputation Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/example_tasks.html">Integrated Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/measures.html">Integrated Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/mlr_publications.html">mlr Publications</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlr-outreach">Talks, Videos and Workshops</a>
    </li>
    <li class="divider">
    <li>
      <a href="https://mlrmbo.mlr-org.com">mlrMBO</a>
    </li>
    <li>
      <a href="https://https://mlrcpo.mlr-org.com">mlrCPO</a>
    </li>
    <li>
      <a href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    </li>
    <li>
      <a href="http://openml.github.io/openml-r/">OpenML</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../news/index.html">Changelog</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
        <li>
  <a href="https://github.com/mlr-org/mlr/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li>
  <a href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right docsearch" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="tune_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Tuning Hyperparameters</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr/blob/master/vignettes/tutorial/tune.Rmd"><code>vignettes/tutorial/tune.Rmd</code></a></small>
      <div class="hidden name"><code>tune.Rmd</code></div>

    </div>

    
    
<p>Many machine learning algorithms have hyperparameters that need to be set. If selected by the user they can be specified as explained on the tutorial page on <a href="learner.html" target="_blank">learners</a> – simply pass them to <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>. Often suitable parameter values are not obvious and it is preferable to tune the hyperparameters, that is automatically identify values that lead to the best performance.</p>
<p>In order to tune a machine learning algorithm, you have to specify:</p>
<ul>
<li>the search space;</li>
<li>the optimization algorithm (aka tuning method);</li>
<li>an evaluation method, i.e., a resampling strategy and a performance measure.</li>
</ul>
<p>An example of the search space could be searching values of the <code>C</code> parameter for <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit">
<span class="co"># ex: create a search space for the C hyperparameter from 0.01 to 0.1</span>
<span class="va">ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeNumericParam</span><span class="op">(</span><span class="st">"C"</span>, lower <span class="op">=</span> <span class="fl">0.01</span>, upper <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>
<span class="op">)</span></pre></div>
<p>An example of the optimization algorithm could be performing random search on the space:</p>
<div class="sourceCode" id="cb2"><pre class="downlit">
<span class="co"># ex: random search with 100 iterations</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlRandom.html">makeTuneControlRandom</a></span><span class="op">(</span>maxit <span class="op">=</span> <span class="fl">100L</span><span class="op">)</span></pre></div>
<p>An example of an evaluation method could be 3-fold CV using accuracy as the performance measure:</p>
<div class="sourceCode" id="cb3"><pre class="downlit">
<span class="va">rdesc</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span>
<span class="va">measure</span> <span class="op">=</span> <span class="va">acc</span></pre></div>
<p>The evaluation method is already covered in detail in <a href="performance.html" target="_blank">evaluation of learning methods</a> and <a href="resample.html" target="_blank">resampling</a>.</p>
<p>In this tutorial, we show how to specify the search space and optimization algorithm, how to do the tuning and how to access the tuning result, and how to visualize the hyperparameter tuning effects through several examples.</p>
<p>Throughout this section we consider classification examples. For the other types of learning problems, you can follow the same process analogously.</p>
<p>We use the iris classification task (<code><a href="../../reference/iris.task.html">iris.task()</a></code>) for illustration and tune the hyperparameters of an SVM (function <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code>) from the <code>kernlab</code> package) with a radial basis kernel. The following examples tune the cost parameter <code>C</code> and the RBF kernel parameter <code>sigma</code> of the <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code>) function.</p>
<div id="specifying-the-search-space" class="section level1">
<h1 class="hasAnchor">
<a href="#specifying-the-search-space" class="anchor"></a>Specifying the search space</h1>
<p>We first must define a space to search when tuning our learner. For example, maybe we want to tune several specific values of a hyperparameter or perhaps we want to define a space from <span class="math inline">\(10^{-10}\)</span> to <span class="math inline">\(10^{10}\)</span> and let the optimization algorithm decide which points to choose.</p>
<p>In order to define a search space, we create a <code>ParamSet</code> (<code><a href="https://paramhelpers.mlr-org.com/reference/makeParamSet.html">ParamHelpers::makeParamSet()</a></code>) object, which describes the parameter space we wish to search. This is done via the function <code><a href="https://paramhelpers.mlr-org.com/reference/makeParamSet.html">ParamHelpers::makeParamSet()</a></code>.</p>
<p>For example, we could define a search space with just the values 0.5, 1.0, 1.5, 2.0 for both <code>C</code> and <code>gamma</code>. Notice how we name each parameter as it’s defined in the <code>kernlab</code> package:</p>
<div class="sourceCode" id="cb4"><pre class="downlit">
<span class="va">discrete_ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"C"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"sigma"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">discrete_ps</span><span class="op">)</span>
<span class="co">##           Type len Def      Constr Req Tunable Trafo</span>
<span class="co">## C     discrete   -   - 0.5,1,1.5,2   -    TRUE     -</span>
<span class="co">## sigma discrete   -   - 0.5,1,1.5,2   -    TRUE     -</span></pre></div>
<p>We could also define a continuous search space (using <code>makeNumericParam</code> (<code><a href="https://paramhelpers.mlr-org.com/reference/Param.html">ParamHelpers::makeNumericParam()</a></code>) instead of <code>makeDiscreteParam</code> (<code><a href="https://paramhelpers.mlr-org.com/reference/Param.html">ParamHelpers::makeDiscreteParam()</a></code>)) from <span class="math inline">\(10^{-10}\)</span> to <span class="math inline">\(10^{10}\)</span> for both parameters through the use of the <code>trafo</code> argument (trafo is short for transformation). Transformations work like this: All optimizers basically see the parameters on their original scale (from <span class="math inline">\(-10\)</span> to <span class="math inline">\(10\)</span> in this case) and produce values on this scale during the search. Right before they are passed to the learning algorithm, the transformation function is applied.</p>
<p>Notice this time we use <code>makeNumericParam</code> (<code><a href="https://paramhelpers.mlr-org.com/reference/Param.html">ParamHelpers::makeNumericParam()</a></code>):</p>
<div class="sourceCode" id="cb5"><pre class="downlit">
<span class="va">num_ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeNumericParam</span><span class="op">(</span><span class="st">"C"</span>, lower <span class="op">=</span> <span class="op">-</span><span class="fl">10</span>, upper <span class="op">=</span> <span class="fl">10</span>, trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">10</span><span class="op">^</span><span class="va">x</span><span class="op">)</span>,
  <span class="fu">makeNumericParam</span><span class="op">(</span><span class="st">"sigma"</span>, lower <span class="op">=</span> <span class="op">-</span><span class="fl">10</span>, upper <span class="op">=</span> <span class="fl">10</span>, trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">10</span><span class="op">^</span><span class="va">x</span><span class="op">)</span>
<span class="op">)</span></pre></div>
<p>Many other parameters can be created, check out the examples in <code><a href="https://paramhelpers.mlr-org.com/reference/makeParamSet.html">ParamHelpers::makeParamSet()</a></code>.</p>
<p>In order to standardize your workflow across several packages, whenever parameters in the underlying <strong>R</strong> functions should be passed in a <code>list</code> structure, <code>mlr</code> tries to give you direct access to each parameter and get rid of the list structure!</p>
<p>This is the case with the <code>kpar</code> argument of <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code>) which is a list of kernel parameters like <code>sigma</code>. This allows us to interface with learners from different packages in the same way when defining parameters to tune!</p>
</div>
<div id="specifying-the-optimization-algorithm" class="section level1">
<h1 class="hasAnchor">
<a href="#specifying-the-optimization-algorithm" class="anchor"></a>Specifying the optimization algorithm</h1>
<p>Now that we have specified the search space, we need to choose an optimization algorithm for our parameters to pass to the <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code>) learner. Optimization algorithms are considered <code><a href="../../reference/TuneControl.html">TuneControl()</a></code> objects in <code>mlr</code>.</p>
<p>A grid search is one of the standard – albeit slow – ways to choose an appropriate set of parameters from a given search space.</p>
<p>In the case of <code>discrete_ps</code> above, since we have manually specified the values, grid search will simply be the cross product. We create the grid search object using the defaults, noting that we will have <span class="math inline">\(4 \times 4 = 16\)</span> combinations in the case of <code>discrete_ps</code>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit">
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span></pre></div>
<p>In the case of <code>num_ps</code> above, since we have only specified the upper and lower bounds for the search space, grid search will create a grid using equally-sized steps. By default, grid search will span the space in 10 equal-sized steps. The number of steps can be changed with the <code>resolution</code> argument. Here we change to 15 equal-sized steps in the space defined within the <code>ParamSet</code> (<code><a href="https://paramhelpers.mlr-org.com/reference/makeParamSet.html">ParamHelpers::makeParamSet()</a></code>) object. For <code>num_ps</code>, this means 15 steps in the form of <code>10 ^ seq(-10, 10, length.out = 15)</code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit">
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span>resolution <span class="op">=</span> <span class="fl">15L</span><span class="op">)</span></pre></div>
<p>Many other types of optimization algorithms are available. Check out <code><a href="../../reference/TuneControl.html">TuneControl()</a></code> for some examples.</p>
<p>Since grid search is normally too slow in practice, we’ll also examine random search. In the case of <code>discrete_ps</code>, random search will randomly choose from the specified values. The <code>maxit</code> argument controls the amount of iterations.</p>
<div class="sourceCode" id="cb8"><pre class="downlit">
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlRandom.html">makeTuneControlRandom</a></span><span class="op">(</span>maxit <span class="op">=</span> <span class="fl">10L</span><span class="op">)</span></pre></div>
<p>In the case of <code>num_ps</code>, random search will randomly choose points within the space according to the specified bounds. Perhaps in this case we would want to increase the amount of iterations to ensure we adequately cover the space:</p>
<div class="sourceCode" id="cb9"><pre class="downlit">
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlRandom.html">makeTuneControlRandom</a></span><span class="op">(</span>maxit <span class="op">=</span> <span class="fl">200L</span><span class="op">)</span></pre></div>
</div>
<div id="performing-the-tuning" class="section level1">
<h1 class="hasAnchor">
<a href="#performing-the-tuning" class="anchor"></a>Performing the tuning</h1>
<p>Now that we have specified a search space and the optimization algorithm, it’s time to perform the tuning. We will need to define a resampling strategy and make note of our performance measure.</p>
<p>We will use 3-fold cross-validation to assess the quality of a specific parameter setting. For this we need to create a resampling description just like in the <a href="resample.html" target="_blank">resampling</a> part of the tutorial.</p>
<div class="sourceCode" id="cb10"><pre class="downlit">
<span class="va">rdesc</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span></pre></div>
<p>Finally, by combining all the previous pieces, we can tune the SVM parameters by calling <code><a href="../../reference/tuneParams.html">tuneParams()</a></code>. We will use <code>discrete_ps</code> with grid search:</p>
<div class="sourceCode" id="cb11"><pre class="downlit">
<span class="va">discrete_ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"C"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"sigma"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">rdesc</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span>
<span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/tuneParams.html">tuneParams</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>, task <span class="op">=</span> <span class="va">iris.task</span>, resampling <span class="op">=</span> <span class="va">rdesc</span>,
  par.set <span class="op">=</span> <span class="va">discrete_ps</span>, control <span class="op">=</span> <span class="va">ctrl</span><span class="op">)</span>
<span class="co">## [Tune] Started tuning learner classif.ksvm for parameter set:</span>
<span class="co">##           Type len Def      Constr Req Tunable Trafo</span>
<span class="co">## C     discrete   -   - 0.5,1,1.5,2   -    TRUE     -</span>
<span class="co">## sigma discrete   -   - 0.5,1,1.5,2   -    TRUE     -</span>
<span class="co">## With control class: TuneControlGrid</span>
<span class="co">## Imputation value: 1</span>
<span class="co">## [Tune-x] 1: C=0.5; sigma=0.5</span>
<span class="co">## [Tune-y] 1: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 2: C=1; sigma=0.5</span>
<span class="co">## [Tune-y] 2: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 3: C=1.5; sigma=0.5</span>
<span class="co">## [Tune-y] 3: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 4: C=2; sigma=0.5</span>
<span class="co">## [Tune-y] 4: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 5: C=0.5; sigma=1</span>
<span class="co">## [Tune-y] 5: mmce.test.mean=0.0533333; time: 0.0 min</span>
<span class="co">## [Tune-x] 6: C=1; sigma=1</span>
<span class="co">## [Tune-y] 6: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 7: C=1.5; sigma=1</span>
<span class="co">## [Tune-y] 7: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 8: C=2; sigma=1</span>
<span class="co">## [Tune-y] 8: mmce.test.mean=0.0400000; time: 0.0 min</span>
<span class="co">## [Tune-x] 9: C=0.5; sigma=1.5</span>
<span class="co">## [Tune-y] 9: mmce.test.mean=0.0533333; time: 0.0 min</span>
<span class="co">## [Tune-x] 10: C=1; sigma=1.5</span>
<span class="co">## [Tune-y] 10: mmce.test.mean=0.0533333; time: 0.0 min</span>
<span class="co">## [Tune-x] 11: C=1.5; sigma=1.5</span>
<span class="co">## [Tune-y] 11: mmce.test.mean=0.0466667; time: 0.0 min</span>
<span class="co">## [Tune-x] 12: C=2; sigma=1.5</span>
<span class="co">## [Tune-y] 12: mmce.test.mean=0.0466667; time: 0.0 min</span>
<span class="co">## [Tune-x] 13: C=0.5; sigma=2</span>
<span class="co">## [Tune-y] 13: mmce.test.mean=0.0600000; time: 0.0 min</span>
<span class="co">## [Tune-x] 14: C=1; sigma=2</span>
<span class="co">## [Tune-y] 14: mmce.test.mean=0.0533333; time: 0.0 min</span>
<span class="co">## [Tune-x] 15: C=1.5; sigma=2</span>
<span class="co">## [Tune-y] 15: mmce.test.mean=0.0466667; time: 0.0 min</span>
<span class="co">## [Tune-x] 16: C=2; sigma=2</span>
<span class="co">## [Tune-y] 16: mmce.test.mean=0.0533333; time: 0.0 min</span>
<span class="co">## [Tune] Result: C=1.5; sigma=0.5 : mmce.test.mean=0.0400000</span>

<span class="va">res</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=1.5; sigma=0.5</span>
<span class="co">## mmce.test.mean=0.0400000</span></pre></div>
<p><code><a href="../../reference/tuneParams.html">tuneParams()</a></code> simply performs the cross-validation for every element of the cross-product and selects the parameter setting with the best mean performance. As no performance measure was specified, by default the error rate (<a href="measures.html" target="_blank">mmce</a>) is used.</p>
<p>Note that each measure (<code><a href="../../reference/makeMeasure.html">makeMeasure()</a></code>) “knows” if it is minimized or maximized during tuning.</p>
<div class="sourceCode" id="cb12"><pre class="downlit">
<span class="co"># error rate</span>
<span class="va">mmce</span><span class="op">$</span><span class="va">minimize</span>
<span class="co">## [1] TRUE</span>

<span class="co"># accuracy</span>
<span class="va">acc</span><span class="op">$</span><span class="va">minimize</span>
<span class="co">## [1] FALSE</span></pre></div>
<p>Of course, you can pass other measures and also a <code>list</code> of measures to <code><a href="../../reference/tuneParams.html">tuneParams()</a></code>. In the latter case the first measure is optimized during tuning, the others are simply evaluated. If you are interested in optimizing several measures simultaneously have a look at <a href="advanced_tune.html" target="_blank">Advanced Tuning</a>.</p>
<p>In the example below we calculate the accuracy (<a href="measures.html" target="_blank">acc</a>) instead of the error rate. We use function <code><a href="../../reference/setAggregation.html">setAggregation()</a></code>, as described on the <a href="resample.html" target="_blank">resampling</a> page, to additionally obtain the standard deviation of the accuracy. We also use random search with 100 iterations on the <code>num_set</code> we defined above and set <code>show.info</code> to <code>FALSE</code> to hide the output for all 100 iterations:</p>
<div class="sourceCode" id="cb13"><pre class="downlit">
<span class="va">num_ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeNumericParam</span><span class="op">(</span><span class="st">"C"</span>, lower <span class="op">=</span> <span class="op">-</span><span class="fl">10</span>, upper <span class="op">=</span> <span class="fl">10</span>, trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">10</span><span class="op">^</span><span class="va">x</span><span class="op">)</span>,
  <span class="fu">makeNumericParam</span><span class="op">(</span><span class="st">"sigma"</span>, lower <span class="op">=</span> <span class="op">-</span><span class="fl">10</span>, upper <span class="op">=</span> <span class="fl">10</span>, trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">10</span><span class="op">^</span><span class="va">x</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlRandom.html">makeTuneControlRandom</a></span><span class="op">(</span>maxit <span class="op">=</span> <span class="fl">100L</span><span class="op">)</span>
<span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/tuneParams.html">tuneParams</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>, task <span class="op">=</span> <span class="va">iris.task</span>, resampling <span class="op">=</span> <span class="va">rdesc</span>, par.set <span class="op">=</span> <span class="va">num_ps</span>,
  control <span class="op">=</span> <span class="va">ctrl</span>, measures <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">acc</span>, <span class="fu"><a href="../../reference/setAggregation.html">setAggregation</a></span><span class="op">(</span><span class="va">acc</span>, <span class="va">test.sd</span><span class="op">)</span><span class="op">)</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">res</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=15.5; sigma=0.0345</span>
<span class="co">## acc.test.mean=0.9600000,acc.test.sd=0.0000000</span></pre></div>
</div>
<div id="accessing-the-tuning-result" class="section level1">
<h1 class="hasAnchor">
<a href="#accessing-the-tuning-result" class="anchor"></a>Accessing the tuning result</h1>
<p>The result object <code><a href="../../reference/TuneResult.html">TuneResult()</a></code> allows you to access the best found settings <code>$x</code> and their estimated performance <code>$y</code>.</p>
<div class="sourceCode" id="cb14"><pre class="downlit">
<span class="va">res</span><span class="op">$</span><span class="va">x</span>
<span class="co">## $C</span>
<span class="co">## [1] 15.52092</span>
<span class="co">## </span>
<span class="co">## $sigma</span>
<span class="co">## [1] 0.03449146</span>

<span class="va">res</span><span class="op">$</span><span class="va">y</span>
<span class="co">## acc.test.mean   acc.test.sd </span>
<span class="co">##          0.96          0.00</span></pre></div>
<p>We can generate a Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) with optimal hyperparameter settings as follows:</p>
<div class="sourceCode" id="cb15"><pre class="downlit">
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/setHyperPars.html">setHyperPars</a></span><span class="op">(</span><span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span><span class="op">)</span>, C <span class="op">=</span> <span class="va">res</span><span class="op">$</span><span class="va">x</span><span class="op">$</span><span class="va">C</span>, sigma <span class="op">=</span> <span class="va">res</span><span class="op">$</span><span class="va">x</span><span class="op">$</span><span class="va">sigma</span><span class="op">)</span>
<span class="va">lrn</span>
<span class="co">## Learner classif.ksvm from package kernlab</span>
<span class="co">## Type: classif</span>
<span class="co">## Name: Support Vector Machines; Short name: ksvm</span>
<span class="co">## Class: classif.ksvm</span>
<span class="co">## Properties: twoclass,multiclass,numerics,factors,prob,class.weights</span>
<span class="co">## Predict-Type: response</span>
<span class="co">## Hyperparameters: fit=FALSE,C=15.5,sigma=0.0345</span></pre></div>
<p>Then you can proceed as usual. Here we refit and predict the learner on the complete iris (<code><a href="https://rdrr.io/r/datasets/iris.html">datasets::iris()</a></code>) data set:</p>
<div class="sourceCode" id="cb16"><pre class="downlit">
<span class="va">m</span> <span class="op">=</span> <span class="fu"><a href="../../reference/train.html">train</a></span><span class="op">(</span><span class="va">lrn</span>, <span class="va">iris.task</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">m</span>, task <span class="op">=</span> <span class="va">iris.task</span><span class="op">)</span>

<span class="co">## Prediction: 150 observations</span>
<span class="co">## predict.type: response</span>
<span class="co">## threshold: </span>
<span class="co">## time: 0.00</span>
<span class="co">##   id  truth response</span>
<span class="co">## 1  1 setosa   setosa</span>
<span class="co">## 2  2 setosa   setosa</span>
<span class="co">## 3  3 setosa   setosa</span>
<span class="co">## 4  4 setosa   setosa</span>
<span class="co">## 5  5 setosa   setosa</span>
<span class="co">## 6  6 setosa   setosa</span>
<span class="co">## ... (#rows: 150, #cols: 3)</span></pre></div>
<p>But what if you wanted to inspect the other points on the search path, not just the optimal?</p>
</div>
<div id="investigating-hyperparameter-tuning-effects" class="section level1">
<h1 class="hasAnchor">
<a href="#investigating-hyperparameter-tuning-effects" class="anchor"></a>Investigating hyperparameter tuning effects</h1>
<p>We can inspect all points evaluated during the search by using <code><a href="../../reference/generateHyperParsEffectData.html">generateHyperParsEffectData()</a></code>:</p>
<div class="sourceCode" id="cb17"><pre class="downlit">
<span class="fu"><a href="../../reference/generateHyperParsEffectData.html">generateHyperParsEffectData</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>
<span class="co">## HyperParsEffectData:</span>
<span class="co">## Hyperparameters: C,sigma</span>
<span class="co">## Measures: acc.test.mean,acc.test.sd</span>
<span class="co">## Optimizer: TuneControlRandom</span>
<span class="co">## Nested CV Used: FALSE</span>
<span class="co">## Snapshot of data:</span>
<span class="co">##            C      sigma acc.test.mean acc.test.sd iteration exec.time</span>
<span class="co">## 1  2.3397773 -3.5124226     0.9466667  0.01154701         1     0.027</span>
<span class="co">## 2  4.0521330 -7.6211727     0.4200000  0.19078784         2     0.029</span>
<span class="co">## 3 -0.9581277 -7.0855536     0.4200000  0.19078784         3     0.029</span>
<span class="co">## 4 -9.7456136 -0.5559055     0.4200000  0.19078784         4     0.030</span>
<span class="co">## 5 -1.1553551  1.1788559     0.3600000  0.08717798         5     0.032</span>
<span class="co">## 6  2.3742768  0.2438430     0.9533333  0.01154701         6     0.030</span></pre></div>
<p>Note that the result of <code><a href="../../reference/generateHyperParsEffectData.html">generateHyperParsEffectData()</a></code> contains the parameter values <em>on the original scale</em>. In order to get the <em>transformed</em> parameter values instead, use the <code>trafo</code> argument:</p>
<div class="sourceCode" id="cb18"><pre class="downlit">
<span class="fu"><a href="../../reference/generateHyperParsEffectData.html">generateHyperParsEffectData</a></span><span class="op">(</span><span class="va">res</span>, trafo <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">## HyperParsEffectData:</span>
<span class="co">## Hyperparameters: C,sigma</span>
<span class="co">## Measures: acc.test.mean,acc.test.sd</span>
<span class="co">## Optimizer: TuneControlRandom</span>
<span class="co">## Nested CV Used: FALSE</span>
<span class="co">## Snapshot of data:</span>
<span class="co">##              C        sigma acc.test.mean acc.test.sd iteration exec.time</span>
<span class="co">## 1 2.186640e+02 3.073105e-04     0.9466667  0.01154701         1     0.027</span>
<span class="co">## 2 1.127543e+04 2.392364e-08     0.4200000  0.19078784         2     0.029</span>
<span class="co">## 3 1.101216e-01 8.211953e-08     0.4200000  0.19078784         3     0.029</span>
<span class="co">## 4 1.796331e-10 2.780318e-01     0.4200000  0.19078784         4     0.030</span>
<span class="co">## 5 6.992701e-02 1.509579e+01     0.3600000  0.08717798         5     0.032</span>
<span class="co">## 6 2.367428e+02 1.753247e+00     0.9533333  0.01154701         6     0.030</span></pre></div>
<p>Note that we can also generate performance on the train data along with the validation/test data, as discussed on the <a href="resample.html" target="_blank">resampling</a> tutorial page:</p>
<div class="sourceCode" id="cb19"><pre class="downlit">
<span class="va">rdesc2</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Holdout"</span>, predict <span class="op">=</span> <span class="st">"both"</span><span class="op">)</span>
<span class="va">res2</span> <span class="op">=</span> <span class="fu"><a href="../../reference/tuneParams.html">tuneParams</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>, task <span class="op">=</span> <span class="va">iris.task</span>, resampling <span class="op">=</span> <span class="va">rdesc2</span>, par.set <span class="op">=</span> <span class="va">num_ps</span>,
  control <span class="op">=</span> <span class="va">ctrl</span>, measures <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">acc</span>, <span class="fu"><a href="../../reference/setAggregation.html">setAggregation</a></span><span class="op">(</span><span class="va">acc</span>, <span class="va">train.mean</span><span class="op">)</span><span class="op">)</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="fu"><a href="../../reference/generateHyperParsEffectData.html">generateHyperParsEffectData</a></span><span class="op">(</span><span class="va">res2</span><span class="op">)</span>
<span class="co">## HyperParsEffectData:</span>
<span class="co">## Hyperparameters: C,sigma</span>
<span class="co">## Measures: acc.test.mean,acc.train.mean</span>
<span class="co">## Optimizer: TuneControlRandom</span>
<span class="co">## Nested CV Used: FALSE</span>
<span class="co">## Snapshot of data:</span>
<span class="co">##           C     sigma acc.test.mean acc.train.mean iteration exec.time</span>
<span class="co">## 1  0.496548 -4.788487          0.64           0.68         1     0.017</span>
<span class="co">## 2  9.095208  8.350293          0.34           1.00         2     0.017</span>
<span class="co">## 3 -1.904618  3.195934          0.34           0.68         3     0.019</span>
<span class="co">## 4  6.863312  1.695167          0.54           1.00         4     0.018</span>
<span class="co">## 5 -1.270327 -6.763619          0.64           0.68         5     0.017</span>
<span class="co">## 6 -8.247310  5.305003          0.32           0.68         6     0.018</span></pre></div>
<p>We can also easily visualize the points evaluated by using <code><a href="../../reference/plotHyperParsEffect.html">plotHyperParsEffect()</a></code>. In the example below, we plot the performance over iterations, using the <code>res</code> from the previous section but instead with 2 performance measures:</p>
<div class="sourceCode" id="cb20"><pre class="downlit">
<span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/tuneParams.html">tuneParams</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>, task <span class="op">=</span> <span class="va">iris.task</span>, resampling <span class="op">=</span> <span class="va">rdesc</span>, par.set <span class="op">=</span> <span class="va">num_ps</span>,
  control <span class="op">=</span> <span class="va">ctrl</span>, measures <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">acc</span>, <span class="va">mmce</span><span class="op">)</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">data</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generateHyperParsEffectData.html">generateHyperParsEffectData</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>
<span class="fu"><a href="../../reference/plotHyperParsEffect.html">plotHyperParsEffect</a></span><span class="op">(</span><span class="va">data</span>, x <span class="op">=</span> <span class="st">"iteration"</span>, y <span class="op">=</span> <span class="st">"acc.test.mean"</span>,
  plot.type <span class="op">=</span> <span class="st">"line"</span><span class="op">)</span></pre></div>
<p><img src="tune_files/figure-html/unnamed-chunk-25-1.png" width="700"></p>
<p>Note that by default, we only plot the current global optima. This can be changed with the <code>global.only</code> argument.</p>
<p>For an in-depth exploration of generating hyperparameter tuning effects and plotting the data, check out <a href="hyperpar_tuning_effects.html" target="_blank">Hyperparameter Tuning Effects</a>.</p>
</div>
<div id="further-comments" class="section level1">
<h1 class="hasAnchor">
<a href="#further-comments" class="anchor"></a>Further comments</h1>
<ul>
<li><p>Tuning works for all other tasks like regression, survival analysis and so on in a completely similar fashion.</p></li>
<li><p>In longer running tuning experiments it is very annoying if the computation stops due to numerical or other errors. Have a look at <code>on.learner.error</code> in <code><a href="../../reference/configureMlr.html">configureMlr()</a></code> as well as the examples given in section <a href="configureMlr.html" target="_blank">configure mlr</a> of this tutorial. You might also want to inform yourself about <code>impute.val</code> in <code><a href="../../reference/TuneControl.html">TuneControl()</a></code>.</p></li>
<li><p>As we continually optimize over the same data during tuning, the estimated performance value might be optimistically biased. A clean approach to ensure unbiased performance estimation is <a href="nested_resampling.html" target="_blank">nested resampling</a>, where we embed the whole model selection process into an outer resampling loop.</p></li>
</ul>
<!--(
.. |tune-varsel_processing| image:: /_img/tune-varsel_processing.png
     :align: middle
     :width: 50em
     :alt: Variable selection as a tuning.

)-->
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Patrick Schratz, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: 'e300ecafdf04fe1199e3339c825ce7d0',
    indexName: 'mlr',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
