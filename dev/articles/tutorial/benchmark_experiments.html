<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Benchmark Experiments • mlr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/journal/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/all.min.css" integrity="sha256-PbSmjxuVAzJ6FPvNYsrXygfGhNJYyZ2GktDbkMBqQZg=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/v4-shims.min.css" integrity="sha256-A6jcAdwFD48VMjlI3GDxUd+eCQa7/KWy6G9oe/ovaPA=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<link href="../../extra.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><!-- docsearch --><script src="../../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Benchmark Experiments">
<meta property="og:description" content="mlr">
<meta property="og:image" content="https://mlr.mlr-org.com/logo.png">
<meta name="twitter:card" content="summary">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a href="https://mlr-org.com"><img src="https://raw.githubusercontent.com/mlr-org/mlr3/master/man/figures/logo.png" id="hexlogo" alt="mlr-org"></a>
        <a class="navbar-brand" href="../../index.html">mlr <small>v2.17.1.9000</small></a>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Task</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learner.html">Learner</a>
    </li>
    <li>
      <a href="../../articles/tutorial/train.html">Train</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmarking</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/usecase_regression.html">Use case - Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/configureMlr.html">mlr Configuration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    </li>
    <li>
      <a href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/handling_of_spatial_data.html">Spatial Data</a>
    </li>
    <li>
      <a href="../../articles/tutorial/functional_data.html">Functional Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extending
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/create_learner.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_measure.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_imputation.html">Create Custom Imputation Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/example_tasks.html">Integrated Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/measures.html">Integrated Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/mlr_publications.html">mlr Publications</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlr-outreach">Talks, Videos and Workshops</a>
    </li>
    <li class="divider">
    <li>
      <a href="https://mlrmbo.mlr-org.com">mlrMBO</a>
    </li>
    <li>
      <a href="https://https://mlrcpo.mlr-org.com">mlrCPO</a>
    </li>
    <li>
      <a href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    </li>
    <li>
      <a href="http://openml.github.io/openml-r/">OpenML</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../news/index.html">Changelog</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
        <li>
  <a href="https://github.com/mlr-org/mlr/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li>
  <a href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right docsearch" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Benchmark Experiments</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr/blob/master/vignettes/tutorial/benchmark_experiments.Rmd"><code>vignettes/tutorial/benchmark_experiments.Rmd</code></a></small>
      <div class="hidden name"><code>benchmark_experiments.Rmd</code></div>

    </div>

    
    
<p>In a benchmark experiment different learning methods are applied to one or several data sets with the aim to compare and rank the algorithms with respect to one or more performance measures.</p>
<p>In <code>mlr</code> a benchmark experiment can be conducted by calling function <code><a href="../../reference/benchmark.html">benchmark()</a></code> on a <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>s and a <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of <code><a href="../../reference/Task.html">Task()</a></code>s. <code><a href="../../reference/benchmark.html">benchmark()</a></code> basically executes <code><a href="../../reference/resample.html">resample()</a></code> for each combination of <code><a href="../../reference/makeLearner.html">makeLearner()</a></code> and <code><a href="../../reference/Task.html">Task()</a></code>. You can specify an individual resampling strategy for each <code><a href="../../reference/Task.html">Task()</a></code> and select one or multiple performance measures to be calculated.</p>
<div id="conducting-benchmark-experiments" class="section level1">
<h1 class="hasAnchor">
<a href="#conducting-benchmark-experiments" class="anchor"></a>Conducting benchmark experiments</h1>
<p>We start with a small example. Two learners, <code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code> and a <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code>, are applied to one classification problem (<code><a href="../../reference/sonar.task.html">sonar.task()</a></code>). As resampling strategy we choose <code>"Holdout"</code>. The performance is thus calculated on a single randomly sampled test data set.</p>
<p>In the example below we create a resample description (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>), which is automatically instantiated by <code><a href="../../reference/benchmark.html">benchmark()</a></code>. The instantiation is done only once per <code><a href="../../reference/Task.html">Task()</a></code>, i.e., the same training and test sets are used for all learners. It is also possible to directly pass a <code><a href="../../reference/makeResampleInstance.html">makeResampleInstance()</a></code>.</p>
<p>If you would like to use a <em>fixed test data set</em> instead of a randomly selected one, you can create a suitable <code><a href="../../reference/makeResampleInstance.html">makeResampleInstance()</a></code> through function <code><a href="../../reference/makeFixedHoldoutInstance.html">makeFixedHoldoutInstance()</a></code>.</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="co"># Two learners to be compared</span>
<span class="no">lrns</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.lda"</span>), <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>))

<span class="co"># Choose the resampling strategy</span>
<span class="no">rdesc</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"Holdout"</span>)

<span class="co"># Conduct the benchmark experiment</span>
<span class="no">bmr</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span>(<span class="no">lrns</span>, <span class="no">sonar.task</span>, <span class="no">rdesc</span>)
<span class="co">## Task: Sonar-example, Learner: classif.lda</span>
<span class="co">## Resampling: holdout</span>
<span class="co">## Measures:             mmce</span>
<span class="co">## [Resample] iter 1:    0.3142857</span>
<span class="co">## </span>
<span class="co">## Aggregated Result: mmce.test.mean=0.3142857</span>
<span class="co">## </span>
<span class="co">## Task: Sonar-example, Learner: classif.rpart</span>
<span class="co">## Resampling: holdout</span>
<span class="co">## Measures:             mmce</span>
<span class="co">## [Resample] iter 1:    0.3285714</span>
<span class="co">## </span>
<span class="co">## Aggregated Result: mmce.test.mean=0.3285714</span>
<span class="co">## </span>

<span class="no">bmr</span>
<span class="co">##         task.id    learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example   classif.lda      0.3142857</span>
<span class="co">## 2 Sonar-example classif.rpart      0.3285714</span></pre></body></html></div>
<p>For convenience, if you don’t want to pass any additional arguments to <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>, you don’t need to generate the <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>s explicitly, but it’s sufficient to provide the learner name. In the above example we could also have written:</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="co"># Vector of strings</span>
<span class="no">lrns</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"classif.lda"</span>, <span class="st">"classif.rpart"</span>)

<span class="co"># A mixed list of Learner objects and strings works, too</span>
<span class="no">lrns</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.lda"</span>, <span class="kw">predict.type</span> <span class="kw">=</span> <span class="st">"prob"</span>), <span class="st">"classif.rpart"</span>)

<span class="no">bmr</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span>(<span class="no">lrns</span>, <span class="no">sonar.task</span>, <span class="no">rdesc</span>, <span class="kw">models</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="co">## Task: Sonar-example, Learner: classif.lda</span>
<span class="co">## Resampling: holdout</span>
<span class="co">## Measures:             mmce</span>
<span class="co">## [Resample] iter 1:    0.3285714</span>
<span class="co">## </span>
<span class="co">## Aggregated Result: mmce.test.mean=0.3285714</span>
<span class="co">## </span>
<span class="co">## Task: Sonar-example, Learner: classif.rpart</span>
<span class="co">## Resampling: holdout</span>
<span class="co">## Measures:             mmce</span>
<span class="co">## [Resample] iter 1:    0.3714286</span>
<span class="co">## </span>
<span class="co">## Aggregated Result: mmce.test.mean=0.3714286</span>
<span class="co">## </span>

<span class="no">bmr</span>
<span class="co">##         task.id    learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example   classif.lda      0.3285714</span>
<span class="co">## 2 Sonar-example classif.rpart      0.3714286</span></pre></body></html></div>
<p>We also need to set <code>models = TRUE</code> explicitly if we want to take a look at them later. By default, models are not stored in the benchmark result object.</p>
<p>In the printed summary table every row corresponds to one pair of <code><a href="../../reference/Task.html">Task()</a></code> and <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>. The entries show the <a href="measures.html" target="_blank">mean misclassification error</a>, the default performance measure for classification, on the test data set.</p>
<p>The result <code>bmr</code> is an object of class <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code>. Basically, it contains a <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of lists of <code><a href="../../reference/ResampleResult.html">ResampleResult()</a></code> objects, first ordered by <code><a href="../../reference/Task.html">Task()</a></code> and then by <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>.</p>
<div id="making-experiments-reproducible" class="section level2">
<h2 class="hasAnchor">
<a href="#making-experiments-reproducible" class="anchor"></a>Making experiments reproducible</h2>
<p>Typically, we would want our experiment results to be reproducible. <code>mlr</code> obeys the <code>set.seed</code> function, so make sure to use <code>set.seed</code> at the beginning of your script if you would like your results to be reproducible.</p>
<p>Note that if you are using parallel computing, you may need to adjust how you call <code>set.seed</code> depending on your usecase. One possibility is to use <code><a href="https://rdrr.io/r/base/Random.html">set.seed(123, "L'Ecuyer")</a></code> in order to ensure the results are reproducible for each child process. See the examples in <code><a href="https://rdrr.io/r/parallel/mclapply.html">parallel::mclapply()</a></code> for more information on reproducibility and parallel computing.</p>
</div>
</div>
<div id="accessing-benchmark-results" class="section level1">
<h1 class="hasAnchor">
<a href="#accessing-benchmark-results" class="anchor"></a>Accessing benchmark results</h1>
<p><code>mlr</code> provides several accessor functions, named <code>getBMR&lt;WhatToExtract&gt;</code>, that permit to retrieve information for further analyses. This includes for example the performances or predictions of the learning algorithms under consideration.</p>
<div id="learner-performances" class="section level2">
<h2 class="hasAnchor">
<a href="#learner-performances" class="anchor"></a>Learner performances</h2>
<p>Let’s have a look at the benchmark result above. <code><a href="../../reference/getBMRPerformances.html">getBMRPerformances()</a></code> returns individual performances in resampling runs, while <code><a href="../../reference/getBMRAggrPerformances.html">getBMRAggrPerformances()</a></code> gives the aggregated values.</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span>(<span class="no">bmr</span>)
<span class="co">## $`Sonar-example`</span>
<span class="co">## $`Sonar-example`$classif.lda</span>
<span class="co">##   iter      mmce</span>
<span class="co">## 1    1 0.3285714</span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`$classif.rpart</span>
<span class="co">##   iter      mmce</span>
<span class="co">## 1    1 0.3714286</span>

<span class="fu"><a href="../../reference/getBMRAggrPerformances.html">getBMRAggrPerformances</a></span>(<span class="no">bmr</span>)
<span class="co">## $`Sonar-example`</span>
<span class="co">## $`Sonar-example`$classif.lda</span>
<span class="co">## mmce.test.mean </span>
<span class="co">##      0.3285714 </span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`$classif.rpart</span>
<span class="co">## mmce.test.mean </span>
<span class="co">##      0.3714286</span></pre></body></html></div>
<p>Since we used holdout as resampling strategy, individual and aggregated performance values coincide.</p>
<p>By default, nearly all “getter” functions return a nested <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code>, with the first level indicating the task and the second level indicating the learner. If only a single learner or, as in our case a single task is considered, setting <code>drop = TRUE</code> simplifies the result to a flat <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code>.</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span>(<span class="no">bmr</span>, <span class="kw">drop</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="co">## $classif.lda</span>
<span class="co">##   iter      mmce</span>
<span class="co">## 1    1 0.3285714</span>
<span class="co">## </span>
<span class="co">## $classif.rpart</span>
<span class="co">##   iter      mmce</span>
<span class="co">## 1    1 0.3714286</span></pre></body></html></div>
<p>Often it is more convenient to work with <code><a href="https://rdrr.io/r/base/data.frame.html">base::data.frame()</a></code>s. You can easily convert the result structure by setting <code>as.df = TRUE</code>.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span>(<span class="no">bmr</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="co">##         task.id    learner.id iter      mmce</span>
<span class="co">## 1 Sonar-example   classif.lda    1 0.3285714</span>
<span class="co">## 2 Sonar-example classif.rpart    1 0.3714286</span>

<span class="fu"><a href="../../reference/getBMRAggrPerformances.html">getBMRAggrPerformances</a></span>(<span class="no">bmr</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="co">##         task.id    learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example   classif.lda      0.3285714</span>
<span class="co">## 2 Sonar-example classif.rpart      0.3714286</span></pre></body></html></div>
</div>
<div id="predictions" class="section level2">
<h2 class="hasAnchor">
<a href="#predictions" class="anchor"></a>Predictions</h2>
<p>Per default, the <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> contains the learner predictions. If you do not want to keep them, e.g., to conserve memory, set <code>keep.pred = FALSE</code> when calling <code><a href="../../reference/benchmark.html">benchmark()</a></code>.</p>
<p>You can access the predictions using function <code><a href="../../reference/getBMRPredictions.html">getBMRPredictions()</a></code>. Per default, you get a nested <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of <code><a href="../../reference/ResamplePrediction.html">ResamplePrediction()</a></code>objects. As above, you can use the <code>drop</code> or <code>as.df</code> options to simplify the result.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRPredictions.html">getBMRPredictions</a></span>(<span class="no">bmr</span>)

<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="fu"><a href="../../reference/getBMRPredictions.html">getBMRPredictions</a></span>(<span class="no">bmr</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>))</pre></body></html></div>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRPredictions.html">getBMRPredictions</a></span>(<span class="no">bmr</span>)

<span class="co">## $`Sonar-example`</span>
<span class="co">## $`Sonar-example`$classif.lda</span>
<span class="co">## Resampled Prediction for:</span>
<span class="co">## Resample description: holdout with 0.67 split rate.</span>
<span class="co">## Predict: test</span>
<span class="co">## Stratification: FALSE</span>
<span class="co">## predict.type: prob</span>
<span class="co">## threshold: M=0.50,R=0.50</span>
<span class="co">## time (mean): 0.00</span>
<span class="co">##    id truth      prob.M       prob.R response iter  set</span>
<span class="co">## 1 194     M 0.001914379 9.980856e-01        R    1 test</span>
<span class="co">## 2  18     R 0.474564117 5.254359e-01        R    1 test</span>
<span class="co">## 3 196     M 0.996712551 3.287449e-03        M    1 test</span>
<span class="co">## 4  10     R 0.001307244 9.986928e-01        R    1 test</span>
<span class="co">## 5 134     M 0.999999755 2.445735e-07        M    1 test</span>
<span class="co">## 6  34     R 0.999761364 2.386361e-04        M    1 test</span>
<span class="co">## ... (#rows: 70, #cols: 7)</span>
<span class="co">##</span>
<span class="co">## $`Sonar-example`$classif.rpart</span>
<span class="co">## Resampled Prediction for:</span>
<span class="co">## Resample description: holdout with 0.67 split rate.</span>
<span class="co">## Predict: test</span>
<span class="co">## Stratification: FALSE</span>
<span class="co">## predict.type: response</span>
<span class="co">## threshold:</span>
<span class="co">## time (mean): 0.00</span>
<span class="co">##    id truth response iter  set</span>
<span class="co">## 1 194     M        M    1 test</span>
<span class="co">## 2  18     R        R    1 test</span>
<span class="co">## 3 196     M        M    1 test</span>
<span class="co">## 4  10     R        R    1 test</span>
<span class="co">## 5 134     M        M    1 test</span>
<span class="co">## 6  34     R        M    1 test</span>
<span class="co">## ... (#rows: 70, #cols: 5)</span>

<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="fu"><a href="../../reference/getBMRPredictions.html">getBMRPredictions</a></span>(<span class="no">bmr</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>))

<span class="co">##         task.id  learner.id  id truth      prob.M       prob.R response</span>
<span class="co">## 1 Sonar-example classif.lda 194     M 0.001914379 9.980856e-01        R</span>
<span class="co">## 2 Sonar-example classif.lda  18     R 0.474564117 5.254359e-01        R</span>
<span class="co">## 3 Sonar-example classif.lda 196     M 0.996712551 3.287449e-03        M</span>
<span class="co">## 4 Sonar-example classif.lda  10     R 0.001307244 9.986928e-01        R</span>
<span class="co">## 5 Sonar-example classif.lda 134     M 0.999999755 2.445735e-07        M</span>
<span class="co">## 6 Sonar-example classif.lda  34     R 0.999761364 2.386361e-04        M</span>
<span class="co">##   iter  set</span>
<span class="co">## 1    1 test</span>
<span class="co">## 2    1 test</span>
<span class="co">## 3    1 test</span>
<span class="co">## 4    1 test</span>
<span class="co">## 5    1 test</span>
<span class="co">## 6    1 test</span></pre></body></html></div>
<p>It is also easily possible to access results for certain learners or tasks via their IDs. For this purpose many “getter” functions have a <code>learner.ids</code> and a <code>task.ids</code> argument.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="fu"><a href="../../reference/getBMRPredictions.html">getBMRPredictions</a></span>(<span class="no">bmr</span>, <span class="kw">learner.ids</span> <span class="kw">=</span> <span class="st">"classif.rpart"</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>))
<span class="co">##         task.id    learner.id  id truth response iter  set</span>
<span class="co">## 1 Sonar-example classif.rpart 112     M        R    1 test</span>
<span class="co">## 2 Sonar-example classif.rpart 191     M        M    1 test</span>
<span class="co">## 3 Sonar-example classif.rpart 208     M        M    1 test</span>
<span class="co">## 4 Sonar-example classif.rpart 203     M        M    1 test</span>
<span class="co">## 5 Sonar-example classif.rpart  23     R        M    1 test</span>
<span class="co">## 6 Sonar-example classif.rpart 162     M        M    1 test</span></pre></body></html></div>
<p>If you don’t like the default IDs, you can set the IDs of learners and tasks via the <code>id</code> option of <code><a href="../../reference/makeLearner.html">makeLearner()</a></code> and <code>makeTask()</code>. Moreover, you can conveniently change the ID of a <code><a href="../../reference/makeLearner.html">makeLearner()</a></code> via function <code>setLearnerid()</code>.</p>
</div>
<div id="ids" class="section level2">
<h2 class="hasAnchor">
<a href="#ids" class="anchor"></a>IDs</h2>
<p>The IDs of all <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>s, <code><a href="../../reference/Task.html">Task()</a></code>s and Measure’s (<code><a href="../../reference/makeMeasure.html">makeMeasure()</a></code>) in a benchmark experiment can be retrieved as follows:</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRTaskIds.html">getBMRTaskIds</a></span>(<span class="no">bmr</span>)
<span class="co">## [1] "Sonar-example"</span>

<span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>)
<span class="co">## [1] "classif.lda"   "classif.rpart"</span>

<span class="fu"><a href="../../reference/getBMRMeasureIds.html">getBMRMeasureIds</a></span>(<span class="no">bmr</span>)
<span class="co">## [1] "mmce"</span></pre></body></html></div>
</div>
<div id="fitted-models" class="section level2">
<h2 class="hasAnchor">
<a href="#fitted-models" class="anchor"></a>Fitted models</h2>
<p>By default the <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> does not contain the fitted models for all learners on all tasks. Since we used <code>models = TRUE</code> when calling <code><a href="../../reference/benchmark.html">benchmark()</a></code>, we can also inspect the created models. The fitted models can be retrieved by function <code><a href="../../reference/getBMRModels.html">getBMRModels()</a></code>. It returns a (possibly nested) <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of <code>WrappedModel</code> (<code><a href="../../reference/makeWrappedModel.html">makeWrappedModel()</a></code>) objects.</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRModels.html">getBMRModels</a></span>(<span class="no">bmr</span>)
<span class="co">## $`Sonar-example`</span>
<span class="co">## $`Sonar-example`$classif.lda</span>
<span class="co">## $`Sonar-example`$classif.lda[[1]]</span>
<span class="co">## Model for learner.id=classif.lda; learner.class=classif.lda</span>
<span class="co">## Trained on: task.id = Sonar-example; obs = 138; features = 60</span>
<span class="co">## Hyperparameters: </span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`$classif.rpart</span>
<span class="co">## $`Sonar-example`$classif.rpart[[1]]</span>
<span class="co">## Model for learner.id=classif.rpart; learner.class=classif.rpart</span>
<span class="co">## Trained on: task.id = Sonar-example; obs = 138; features = 60</span>
<span class="co">## Hyperparameters: xval=0</span>

<span class="fu"><a href="../../reference/getBMRModels.html">getBMRModels</a></span>(<span class="no">bmr</span>, <span class="kw">drop</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="co">## $classif.lda</span>
<span class="co">## $classif.lda[[1]]</span>
<span class="co">## Model for learner.id=classif.lda; learner.class=classif.lda</span>
<span class="co">## Trained on: task.id = Sonar-example; obs = 138; features = 60</span>
<span class="co">## Hyperparameters: </span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## $classif.rpart</span>
<span class="co">## $classif.rpart[[1]]</span>
<span class="co">## Model for learner.id=classif.rpart; learner.class=classif.rpart</span>
<span class="co">## Trained on: task.id = Sonar-example; obs = 138; features = 60</span>
<span class="co">## Hyperparameters: xval=0</span>

<span class="fu"><a href="../../reference/getBMRModels.html">getBMRModels</a></span>(<span class="no">bmr</span>, <span class="kw">learner.ids</span> <span class="kw">=</span> <span class="st">"classif.lda"</span>)
<span class="co">## $`Sonar-example`</span>
<span class="co">## $`Sonar-example`$classif.lda</span>
<span class="co">## $`Sonar-example`$classif.lda[[1]]</span>
<span class="co">## Model for learner.id=classif.lda; learner.class=classif.lda</span>
<span class="co">## Trained on: task.id = Sonar-example; obs = 138; features = 60</span>
<span class="co">## Hyperparameters:</span></pre></body></html></div>
</div>
<div id="learners-and-measures" class="section level2">
<h2 class="hasAnchor">
<a href="#learners-and-measures" class="anchor"></a>Learners and measures</h2>
<p>Moreover, you can extract the employed <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>s and Measure’s (<code><a href="../../reference/makeMeasure.html">makeMeasure()</a></code>).</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="fu"><a href="../../reference/getBMRLearners.html">getBMRLearners</a></span>(<span class="no">bmr</span>)
<span class="co">## $classif.lda</span>
<span class="co">## Learner classif.lda from package MASS</span>
<span class="co">## Type: classif</span>
<span class="co">## Name: Linear Discriminant Analysis; Short name: lda</span>
<span class="co">## Class: classif.lda</span>
<span class="co">## Properties: twoclass,multiclass,numerics,factors,prob</span>
<span class="co">## Predict-Type: prob</span>
<span class="co">## Hyperparameters: </span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## $classif.rpart</span>
<span class="co">## Learner classif.rpart from package rpart</span>
<span class="co">## Type: classif</span>
<span class="co">## Name: Decision Tree; Short name: rpart</span>
<span class="co">## Class: classif.rpart</span>
<span class="co">## Properties: twoclass,multiclass,missings,numerics,factors,ordered,prob,weights,featimp</span>
<span class="co">## Predict-Type: response</span>
<span class="co">## Hyperparameters: xval=0</span>

<span class="fu"><a href="../../reference/getBMRMeasures.html">getBMRMeasures</a></span>(<span class="no">bmr</span>)
<span class="co">## [[1]]</span>
<span class="co">## Name: Mean misclassification error</span>
<span class="co">## Performance measure: mmce</span>
<span class="co">## Properties: classif,classif.multi,req.pred,req.truth</span>
<span class="co">## Minimize: TRUE</span>
<span class="co">## Best: 0; Worst: 1</span>
<span class="co">## Aggregated by: test.mean</span>
<span class="co">## Arguments: </span>
<span class="co">## Note: Defined as: mean(response != truth)</span></pre></body></html></div>
</div>
</div>
<div id="merging-benchmark-results" class="section level1">
<h1 class="hasAnchor">
<a href="#merging-benchmark-results" class="anchor"></a>Merging benchmark results</h1>
<p>Sometimes after completing a benchmark experiment it turns out that you want to extend it by another <code><a href="../../reference/makeLearner.html">makeLearner()</a></code> or another <code><a href="../../reference/Task.html">Task()</a></code>. In this case you can perform an additional benchmark experiment and then use function <code><a href="../../reference/mergeBenchmarkResults.html">mergeBenchmarkResults()</a></code> to combine the results to a single <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> object that can be accessed and analyzed as usual.</p>
<p>For example in the benchmark experiment above we applied <code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code> and <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code> to the <code><a href="../../reference/sonar.task.html">sonar.task()</a></code>. We now perform a second experiment using a <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code> and quadratic discriminant analysis <code><a href="https://rdrr.io/pkg/MASS/man/qda.html">MASS::qda()</a></code> and merge the results.</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="co"># First benchmark result</span>
<span class="no">bmr</span>
<span class="co">##         task.id    learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example   classif.lda      0.3285714</span>
<span class="co">## 2 Sonar-example classif.rpart      0.3714286</span>

<span class="co"># Benchmark experiment for the additional learners</span>
<span class="no">lrns2</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.randomForest"</span>), <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.qda"</span>))
<span class="no">bmr2</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span>(<span class="no">lrns2</span>, <span class="no">sonar.task</span>, <span class="no">rdesc</span>, <span class="kw">show.info</span> <span class="kw">=</span> <span class="fl">FALSE</span>)
<span class="no">bmr2</span>
<span class="co">##         task.id           learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example classif.randomForest      0.1285714</span>
<span class="co">## 2 Sonar-example          classif.qda      0.4000000</span>

<span class="co"># Merge the results</span>
<span class="fu"><a href="../../reference/mergeBenchmarkResults.html">mergeBenchmarkResults</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="no">bmr</span>, <span class="no">bmr2</span>))
<span class="co">##         task.id           learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example          classif.lda      0.3285714</span>
<span class="co">## 2 Sonar-example        classif.rpart      0.3714286</span>
<span class="co">## 3 Sonar-example classif.randomForest      0.1285714</span>
<span class="co">## 4 Sonar-example          classif.qda      0.4000000</span></pre></body></html></div>
<p>Note that in the above examples in each case a resample description (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>) was passed to the <code><a href="../../reference/benchmark.html">benchmark()</a></code> function. For this reason <code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code> and <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code> were most likely evaluated on a different training/test set pair than <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code> and <code><a href="https://rdrr.io/pkg/MASS/man/qda.html">MASS::qda()</a></code>.</p>
<p>Differing training/test set pairs across learners pose an additional source of variation in the results, which can make it harder to detect actual performance differences between learners. Therefore, if you suspect that you will have to extend your benchmark experiment by another <code><a href="../../reference/makeLearner.html">makeLearner()</a></code> later on it’s probably easiest to work with <code><a href="../../reference/makeResampleInstance.html">makeResampleInstance()</a></code>s from the start. These can be stored and used for any additional experiments.</p>
<p>Alternatively, if you used a resample description in the first benchmark experiment you could also extract the <code><a href="../../reference/makeResampleInstance.html">makeResampleInstance()</a></code>s from the <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> <code>bmr</code> and pass these to all further <code><a href="../../reference/benchmark.html">benchmark()</a></code> calls.</p>
<div class="sourceCode" id="cb13"><html><body><pre class="r"><span class="no">rin</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRPredictions.html">getBMRPredictions</a></span>(<span class="no">bmr</span>)<span class="kw">[[</span><span class="fl">1</span>]]<span class="kw">[[</span><span class="fl">1</span>]]$<span class="no">instance</span>
<span class="no">rin</span>
<span class="co">## Resample instance for 208 cases.</span>
<span class="co">## Resample description: holdout with 0.67 split rate.</span>
<span class="co">## Predict: test</span>
<span class="co">## Stratification: FALSE</span>

<span class="co"># Benchmark experiment for the additional random forest</span>
<span class="no">bmr3</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span>(<span class="no">lrns2</span>, <span class="no">sonar.task</span>, <span class="no">rin</span>, <span class="kw">show.info</span> <span class="kw">=</span> <span class="fl">FALSE</span>)
<span class="no">bmr3</span>
<span class="co">##         task.id           learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example classif.randomForest      0.1428571</span>
<span class="co">## 2 Sonar-example          classif.qda      0.3285714</span>

<span class="co"># Merge the results</span>
<span class="fu"><a href="../../reference/mergeBenchmarkResults.html">mergeBenchmarkResults</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="no">bmr</span>, <span class="no">bmr3</span>))
<span class="co">##         task.id           learner.id mmce.test.mean</span>
<span class="co">## 1 Sonar-example          classif.lda      0.3285714</span>
<span class="co">## 2 Sonar-example        classif.rpart      0.3714286</span>
<span class="co">## 3 Sonar-example classif.randomForest      0.1428571</span>
<span class="co">## 4 Sonar-example          classif.qda      0.3285714</span></pre></body></html></div>
</div>
<div id="benchmark-analysis-and-visualization" class="section level1">
<h1 class="hasAnchor">
<a href="#benchmark-analysis-and-visualization" class="anchor"></a>Benchmark analysis and visualization</h1>
<p><code>mlr</code> offers several ways to analyze the results of a benchmark experiment. This includes visualization, ranking of learning algorithms and hypothesis tests to assess performance differences between learners.</p>
<p>In order to demonstrate the functionality we conduct a slightly larger benchmark experiment with three learning algorithms that are applied to five classification tasks.</p>
<div id="example-comparing-lda-rpart-and-random-forest" class="section level2">
<h2 class="hasAnchor">
<a href="#example-comparing-lda-rpart-and-random-forest" class="anchor"></a>Example: Comparing lda, rpart and random Forest</h2>
<p>We consider <code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code>, classification trees <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code>, and random forests <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code>. Since the default learner IDs are a little long, we choose shorter names in the <strong>R</strong> code below.</p>
<p>We use five classification tasks. Three are already provided by <code>mlr</code>, two more data sets are taken from package <code>mlbench::mlbench()</code> and converted to <code><a href="../../reference/Task.html">Task()</a></code>s by function <code><a href="../../reference/convertMLBenchObjToTask.html">convertMLBenchObjToTask()</a></code>.</p>
<p>For all tasks 10-fold cross-validation is chosen as resampling strategy. This is achieved by passing a single resample description (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>) to <code><a href="../../reference/benchmark.html">benchmark()</a></code>, which is then instantiated automatically once for each <code><a href="../../reference/Task.html">Task()</a></code>. This way, the same instance is used for all learners applied to a single task.</p>
<p>It is also possible to choose a different resampling strategy for each <code><a href="../../reference/Task.html">Task()</a></code> by passing a <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of the same length as the number of tasks that can contain both resample descriptions (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>) and resample instances (<code><a href="../../reference/makeResampleInstance.html">makeResampleInstance()</a></code>).</p>
<p>We use the mean misclassification error <a href="measures.html" target="_blank">mmce</a> as primary performance measure, but also calculate the balanced error rate <a href="measures.html" target="_blank">ber</a> and the training time <code>timetrain</code>.</p>
<pre><code>## Loading required package: mlbench</code></pre>
<div class="sourceCode" id="cb15"><html><body><pre class="r"><span class="co"># Create a list of learners</span>
<span class="no">lrns</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(
  <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.lda"</span>, <span class="kw">id</span> <span class="kw">=</span> <span class="st">"lda"</span>),
  <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>, <span class="kw">id</span> <span class="kw">=</span> <span class="st">"rpart"</span>),
  <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.randomForest"</span>, <span class="kw">id</span> <span class="kw">=</span> <span class="st">"randomForest"</span>)
)

<span class="co"># Get additional Tasks from package mlbench</span>
<span class="no">ring.task</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/convertMLBenchObjToTask.html">convertMLBenchObjToTask</a></span>(<span class="st">"mlbench.ringnorm"</span>, <span class="kw">n</span> <span class="kw">=</span> <span class="fl">600</span>)
<span class="no">wave.task</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/convertMLBenchObjToTask.html">convertMLBenchObjToTask</a></span>(<span class="st">"mlbench.waveform"</span>, <span class="kw">n</span> <span class="kw">=</span> <span class="fl">600</span>)

<span class="no">tasks</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="no">iris.task</span>, <span class="no">sonar.task</span>, <span class="no">pid.task</span>, <span class="no">ring.task</span>, <span class="no">wave.task</span>)
<span class="no">rdesc</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"CV"</span>, <span class="kw">iters</span> <span class="kw">=</span> <span class="fl">10</span>)
<span class="no">meas</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="no">mmce</span>, <span class="no">ber</span>, <span class="no">timetrain</span>)
<span class="no">bmr</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span>(<span class="no">lrns</span>, <span class="no">tasks</span>, <span class="no">rdesc</span>, <span class="no">meas</span>, <span class="kw">show.info</span> <span class="kw">=</span> <span class="fl">FALSE</span>)

<span class="co">##                        task.id   learner.id mmce.test.mean ber.test.mean</span>
<span class="co">## 1                 iris-example          lda     0.02000000    0.02222222</span>
<span class="co">## 2                 iris-example        rpart     0.08000000    0.07555556</span>
<span class="co">## 3                 iris-example randomForest     0.05333333    0.05250000</span>
<span class="co">## 4             mlbench.ringnorm          lda     0.35000000    0.34605671</span>
<span class="co">## 5             mlbench.ringnorm        rpart     0.17333333    0.17313632</span>
<span class="co">## 6             mlbench.ringnorm randomForest     0.05666667    0.05724405</span>
<span class="co">## 7             mlbench.waveform          lda     0.19000000    0.18257244</span>
<span class="co">## 8             mlbench.waveform        rpart     0.28833333    0.28765247</span>
<span class="co">## 9             mlbench.waveform randomForest     0.17500000    0.17418440</span>
<span class="co">## 10 PimaIndiansDiabetes-example          lda     0.22778537    0.27148893</span>
<span class="co">## 11 PimaIndiansDiabetes-example        rpart     0.25133288    0.28967870</span>
<span class="co">## 12 PimaIndiansDiabetes-example randomForest     0.23427888    0.27464510</span>
<span class="co">## 13               Sonar-example          lda     0.24619048    0.23986694</span>
<span class="co">## 14               Sonar-example        rpart     0.30785714    0.31153361</span>
<span class="co">## 15               Sonar-example randomForest     0.18738095    0.18359363</span>
<span class="co">##    timetrain.test.mean</span>
<span class="co">## 1               0.0039</span>
<span class="co">## 2               0.0048</span>
<span class="co">## 3               0.0330</span>
<span class="co">## 4               0.0092</span>
<span class="co">## 5               0.0116</span>
<span class="co">## 6               0.3548</span>
<span class="co">## 7               0.0084</span>
<span class="co">## 8               0.0100</span>
<span class="co">## 9               0.3675</span>
<span class="co">## 10              0.0424</span>
<span class="co">## 11              0.0066</span>
<span class="co">## 12              0.4108</span>
<span class="co">## 13              0.0147</span>
<span class="co">## 14              0.0128</span>
<span class="co">## 15              0.2335</span></pre></body></html></div>
<p>From the aggregated performance values we can see that for the iris- and PimaIndiansDiabetes-example linear discriminant analysis (<code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code>) performs well while for all other tasks the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code> seems superior. Training takes longer for the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code> than for the other learners.</p>
<p>In order to draw any conclusions from the average performances at least their variability has to be taken into account or, preferably, the distribution of performance values across resampling iterations.</p>
<p>The individual performances on the 10 folds for every task, learner, and measure are retrieved below.</p>
<div class="sourceCode" id="cb16"><html><body><pre class="r"><span class="no">perf</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span>(<span class="no">bmr</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">perf</span>[, -<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">perf</span>)])
<span class="co">##        task.id learner.id iter       mmce        ber</span>
<span class="co">## 1 iris-example        lda    1 0.06666667 0.05555556</span>
<span class="co">## 2 iris-example        lda    2 0.00000000 0.00000000</span>
<span class="co">## 3 iris-example        lda    3 0.06666667 0.04761905</span>
<span class="co">## 4 iris-example        lda    4 0.00000000 0.00000000</span>
<span class="co">## 5 iris-example        lda    5 0.06666667 0.04166667</span>
<span class="co">## 6 iris-example        lda    6 0.00000000 0.00000000</span></pre></body></html></div>
<p>A closer look at the result reveals that the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code> outperforms the classification tree (<code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code>) in every instance, while linear discriminant analysis (<code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code>) performs better than <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code> most of the time. Additionally <code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code> sometimes even beats the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code>. With increasing size of such <code><a href="../../reference/benchmark.html">benchmark()</a></code> experiments, those tables become almost unreadable and hard to comprehend.</p>
<p><code>mlr</code> features some plotting functions to visualize results of benchmark experiments that you might find useful. Moreover, <code>mlr</code> offers statistical hypothesis tests to assess performance differences between learners.</p>
</div>
<div id="integrated-plots" class="section level2">
<h2 class="hasAnchor">
<a href="#integrated-plots" class="anchor"></a>Integrated plots</h2>
<p>Plots are generated using <code><a href="https://ggplot2.tidyverse.org/reference/ggplot2-package.html">ggplot2::ggplot2()</a></code>. Further customization, such as renaming plot elements or changing colors, is easily possible.</p>
<div id="visualizing-performances" class="section level3">
<h3 class="hasAnchor">
<a href="#visualizing-performances" class="anchor"></a>Visualizing performances</h3>
<p><code><a href="../../reference/plotBMRBoxplots.html">plotBMRBoxplots()</a></code> creates box or violin plots which show the distribution of performance values across resampling iterations for one performance measure and for all learners and tasks (and thus visualize the output of <code><a href="../../reference/getBMRPerformances.html">getBMRPerformances()</a></code>).</p>
<p>Below are both variants, box and violin plots. The first plot shows the <a href="measures.html" target="_blank">mmce</a> and the second plot the <a href="measures.html" target="_blank">ber</a>. Moreover, in the second plot we color the boxes according to the <code>learner.id</code>s.</p>
<div class="sourceCode" id="cb17"><html><body><pre class="r"><span class="fu"><a href="../../reference/plotBMRBoxplots.html">plotBMRBoxplots</a></span>(<span class="no">bmr</span>, <span class="kw">measure</span> <span class="kw">=</span> <span class="no">mmce</span>, <span class="kw">order.lrn</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>))</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-18-1.png" width="700"></p>
<div class="sourceCode" id="cb18"><html><body><pre class="r"><span class="fu"><a href="../../reference/plotBMRBoxplots.html">plotBMRBoxplots</a></span>(<span class="no">bmr</span>, <span class="kw">measure</span> <span class="kw">=</span> <span class="no">ber</span>, <span class="kw">style</span> <span class="kw">=</span> <span class="st">"violin"</span>, <span class="kw">pretty.names</span> <span class="kw">=</span> <span class="fl">FALSE</span>,
  <span class="kw">order.lrn</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>)) +
  <span class="fu">aes</span>(<span class="kw">color</span> <span class="kw">=</span> <span class="no">learner.id</span>) +
  <span class="fu">theme</span>(<span class="kw">strip.text.x</span> <span class="kw">=</span> <span class="fu">element_text</span>(<span class="kw">size</span> <span class="kw">=</span> <span class="fl">8</span>))
<span class="co">## Warning: `fun.y` is deprecated. Use `fun` instead.</span>
<span class="co">## Warning: `fun.ymin` is deprecated. Use `fun.min` instead.</span>
<span class="co">## Warning: `fun.ymax` is deprecated. Use `fun.max` instead.</span></pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-18-2.png" width="700"></p>
<p>Note that by default the measure <code>name</code>s and the learner <code>short.name</code>s are used as axis labels.</p>
<div class="sourceCode" id="cb19"><html><body><pre class="r"><span class="no">mmce</span>$<span class="no">name</span>
<span class="co">## [1] "Mean misclassification error"</span>

<span class="no">mmce</span>$<span class="no">id</span>
<span class="co">## [1] "mmce"</span>

<span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>)
<span class="co">## [1] "lda"          "rpart"        "randomForest"</span>

<span class="fu"><a href="../../reference/getBMRLearnerShortNames.html">getBMRLearnerShortNames</a></span>(<span class="no">bmr</span>)
<span class="co">## [1] "lda"   "rpart" "rf"</span></pre></body></html></div>
<p>If you prefer the <code>id</code>s like, e.g., mmce and ber set <code>pretty.names = FALSE</code> (as done for the second plot). Of course you can also use the <code><a href="https://ggplot2.tidyverse.org/reference/ggplot2-package.html">ggplot2::ggplot2()</a></code> functionality like the <code><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggplot2::labs()</a></code> function to choose completely different labels.</p>
<p>One question which comes up quite often is how to change the panel headers (which default to the <code><a href="../../reference/Task.html">Task()</a></code> IDs) and the learner names on the x-axis. For example looking at the above plots we would like to remove the “example” suffixes and the “mlbench” prefixes from the panel headers. Moreover, we want uppercase learner labels. Currently, the probably simplest solution is to change the factor levels of the plotted data as shown below.</p>
<div class="sourceCode" id="cb20"><html><body><pre class="r"><span class="no">plt</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/plotBMRBoxplots.html">plotBMRBoxplots</a></span>(<span class="no">bmr</span>, <span class="kw">measure</span> <span class="kw">=</span> <span class="no">mmce</span>, <span class="kw">order.lrn</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>))
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">plt</span>$<span class="no">data</span>[, -<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">plt</span>$<span class="no">data</span>)])
<span class="co">##        task.id learner.id iter       mmce        ber</span>
<span class="co">## 1 iris-example        lda    1 0.06666667 0.05555556</span>
<span class="co">## 2 iris-example        lda    2 0.00000000 0.00000000</span>
<span class="co">## 3 iris-example        lda    3 0.06666667 0.04761905</span>
<span class="co">## 4 iris-example        lda    4 0.00000000 0.00000000</span>
<span class="co">## 5 iris-example        lda    5 0.06666667 0.04166667</span>
<span class="co">## 6 iris-example        lda    6 0.00000000 0.00000000</span>

<span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span>(<span class="no">plt</span>$<span class="no">data</span>$<span class="no">task.id</span>) <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Iris"</span>, <span class="st">"Ringnorm"</span>, <span class="st">"Waveform"</span>, <span class="st">"Diabetes"</span>, <span class="st">"Sonar"</span>)
<span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span>(<span class="no">plt</span>$<span class="no">data</span>$<span class="no">learner.id</span>) <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"LDA"</span>, <span class="st">"CART"</span>, <span class="st">"RF"</span>)

<span class="no">plt</span> + <span class="fu">ylab</span>(<span class="st">"Error rate"</span>)</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-20-1.png" width="700"></p>
</div>
<div id="visualizing-aggregated-performances" class="section level3">
<h3 class="hasAnchor">
<a href="#visualizing-aggregated-performances" class="anchor"></a>Visualizing aggregated performances</h3>
<p>The aggregated performance values (resulting from <code><a href="../../reference/getBMRAggrPerformances.html">getBMRAggrPerformances()</a></code>) can be visualized by function <code><a href="../../reference/plotBMRSummary.html">plotBMRSummary()</a></code>. This plot draws one line for each task on which the aggregated values of one performance measure for all learners are displayed. By default, the first measure in the <code><a href="https://rdrr.io/r/base/list.html">base::list()</a></code> of Measure’s (<code><a href="../../reference/makeMeasure.html">makeMeasure()</a></code>) passed to <code><a href="../../reference/benchmark.html">benchmark()</a></code> is used, in our example <a href="measures.html" target="_blank">mmce</a>. Moreover, a small vertical jitter is added to prevent overplotting.</p>
<div class="sourceCode" id="cb21"><html><body><pre class="r"><span class="fu"><a href="../../reference/plotBMRSummary.html">plotBMRSummary</a></span>(<span class="no">bmr</span>)</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-21-1.png" width="700"></p>
</div>
<div id="calculating-and-visualizing-ranks" class="section level3">
<h3 class="hasAnchor">
<a href="#calculating-and-visualizing-ranks" class="anchor"></a>Calculating and visualizing ranks</h3>
<p>Additional to the absolute performance, relative performance, i.e., ranking the learners is usually of interest and might provide valuable additional insight.</p>
<p>Function <code><a href="../../reference/convertBMRToRankMatrix.html">convertBMRToRankMatrix()</a></code> calculates ranks based on aggregated learner performances of one measure. We choose the <a href="measures.html" target="_blank">mean misclassification error</a>. The rank structure can be visualized by <code><a href="../../reference/plotBMRRanksAsBarChart.html">plotBMRRanksAsBarChart()</a></code>.</p>
<div class="sourceCode" id="cb22"><html><body><pre class="r"><span class="no">m</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/convertBMRToRankMatrix.html">convertBMRToRankMatrix</a></span>(<span class="no">bmr</span>, <span class="no">mmce</span>)
<span class="no">m</span>
<span class="co">##              iris-example mlbench.ringnorm mlbench.waveform</span>
<span class="co">## lda                     1                3                2</span>
<span class="co">## rpart                   3                2                3</span>
<span class="co">## randomForest            2                1                1</span>
<span class="co">##              PimaIndiansDiabetes-example Sonar-example</span>
<span class="co">## lda                                    1             2</span>
<span class="co">## rpart                                  3             3</span>
<span class="co">## randomForest                           2             1</span></pre></body></html></div>
<p>Methods with best performance, i.e., with lowest <a href="measures.html" target="_blank">mmce</a>, are assigned the lowest rank. Linear discriminant analysis (<code><a href="https://rdrr.io/pkg/MASS/man/lda.html">MASS::lda()</a></code>) is best for the iris and PimaIndiansDiabetes-examples while the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code> shows best results on the remaining tasks.</p>
<p><code><a href="../../reference/plotBMRRanksAsBarChart.html">plotBMRRanksAsBarChart()</a></code> with option <code>pos = "tile"</code> shows a corresponding heat map. The ranks are displayed on the x-axis and the learners are color-coded.</p>
<div class="sourceCode" id="cb23"><html><body><pre class="r"><span class="fu"><a href="../../reference/plotBMRRanksAsBarChart.html">plotBMRRanksAsBarChart</a></span>(<span class="no">bmr</span>, <span class="kw">pos</span> <span class="kw">=</span> <span class="st">"tile"</span>, <span class="kw">order.lrn</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>))</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
<p>A similar plot can also be obtained via <code><a href="../../reference/plotBMRSummary.html">plotBMRSummary()</a></code>. With option <code>trafo = "rank"</code> the ranks are displayed instead of the aggregated performances.</p>
<div class="sourceCode" id="cb24"><html><body><pre class="r"><span class="fu"><a href="../../reference/plotBMRSummary.html">plotBMRSummary</a></span>(<span class="no">bmr</span>, <span class="kw">trafo</span> <span class="kw">=</span> <span class="st">"rank"</span>, <span class="kw">jitter</span> <span class="kw">=</span> <span class="fl">0</span>)</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-24-1.png" width="700"></p>
<p>Alternatively, you can draw stacked bar charts (the default) or bar charts with juxtaposed bars (<code>pos = "dodge"</code>) that are better suited to compare the frequencies of learners within and across ranks.</p>
<div class="sourceCode" id="cb25"><html><body><pre class="r"><span class="fu"><a href="../../reference/plotBMRRanksAsBarChart.html">plotBMRRanksAsBarChart</a></span>(<span class="no">bmr</span>, <span class="kw">order.lrn</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>))
<span class="fu"><a href="../../reference/plotBMRRanksAsBarChart.html">plotBMRRanksAsBarChart</a></span>(<span class="no">bmr</span>, <span class="kw">pos</span> <span class="kw">=</span> <span class="st">"dodge"</span>, <span class="kw">order.lrn</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRLearnerIds.html">getBMRLearnerIds</a></span>(<span class="no">bmr</span>))</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-25-1.png" width="50%"><img src="benchmark_experiments_files/figure-html/unnamed-chunk-25-2.png" width="50%"></p>
</div>
</div>
<div id="comparing-learners-using-hypothesis-tests" class="section level2">
<h2 class="hasAnchor">
<a href="#comparing-learners-using-hypothesis-tests" class="anchor"></a>Comparing learners using hypothesis tests</h2>
<p>Many researchers feel the need to display an algorithm’s superiority by employing some sort of hypothesis testing. As non-parametric tests seem better suited for such benchmark results the tests provided in <code>mlr</code> are the <strong>Overall Friedman test</strong> and the <strong>Friedman-Nemenyi post hoc test</strong>.</p>
<p>While the ad hoc <code><a href="../../reference/friedmanTestBMR.html">friedmanTestBMR()</a></code> based on <code><a href="https://rdrr.io/r/stats/friedman.test.html">stats::friedman.test()</a></code> is testing the hypothesis whether there is a significant difference between the employed learners, the post hoc <code><a href="../../reference/friedmanPostHocTestBMR.html">friedmanPostHocTestBMR()</a></code> tests for significant differences between all pairs of learners. <em>Non parametric</em> tests often do have less power then their <em>parametric</em> counterparts but less assumptions about underlying distributions have to be made. This often means many <strong>data sets</strong> are needed in order to be able to show significant differences at reasonable significance levels.</p>
<p>In our example, we want to compare the three learners on the selected data sets. First we might we want to test the hypothesis whether there is a difference between the learners.</p>
<div class="sourceCode" id="cb26"><html><body><pre class="r"><span class="fu"><a href="../../reference/friedmanTestBMR.html">friedmanTestBMR</a></span>(<span class="no">bmr</span>)
<span class="co">## </span>
<span class="co">##  Friedman rank sum test</span>
<span class="co">## </span>
<span class="co">## data:  mmce.test.mean and learner.id and task.id</span>
<span class="co">## Friedman chi-squared = 5.2, df = 2, p-value = 0.07427</span></pre></body></html></div>
<p>In order to keep the computation time for this tutorial small, the <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>s are only evaluated on five tasks. This also means that we operate on a relatively low significance level <span class="math inline">\(\alpha = 0.1\)</span>. As we can reject the null hypothesis of the Friedman test at a reasonable significance level we might now want to test where these differences lie exactly.</p>
<div class="sourceCode" id="cb27"><html><body><pre class="r"><span class="fu"><a href="../../reference/friedmanPostHocTestBMR.html">friedmanPostHocTestBMR</a></span>(<span class="no">bmr</span>, <span class="kw">p.value</span> <span class="kw">=</span> <span class="fl">0.1</span>)
<span class="co">## </span>
<span class="co">##  Pairwise comparisons using Nemenyi multiple comparison test </span>
<span class="co">##              with q approximation for unreplicated blocked data </span>
<span class="co">## </span>
<span class="co">## data:  mmce.test.mean and learner.id and task.id </span>
<span class="co">## </span>
<span class="co">##              lda   rpart</span>
<span class="co">## rpart        0.254 -    </span>
<span class="co">## randomForest 0.802 0.069</span>
<span class="co">## </span>
<span class="co">## P value adjustment method: none</span></pre></body></html></div>
<p>At this level of significance, we can reject the null hypothesis that there exists no performance difference between the decision tree (<code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code>) and the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest::randomForest()</a></code>.</p>
</div>
<div id="critical-differences-diagram" class="section level2">
<h2 class="hasAnchor">
<a href="#critical-differences-diagram" class="anchor"></a>Critical differences diagram</h2>
<p>In order to visualize differently performing learners, a critical differences diagramcan be plotted, using either the Nemenyi test (<code>test = "nemenyi"</code>) or the Bonferroni-Dunn test (<code>test = "bd"</code>).</p>
<p>The mean rank of learners is displayed on the x-axis.</p>
<ul>
<li>Choosing <code>test = "nemenyi"</code> compares all pairs of <code><a href="../../reference/makeLearner.html">makeLearner()</a></code>s to each other, thus the output are groups of not significantly different learners. The diagram connects all groups of learners where the mean ranks do not differ by more than the critical differences. Learners that are not connected by a bar are significantly different, and the learner(s) with the lower mean rank can be considered “better” at the chosen significance level.</li>
<li>Choosing <code>test = "bd"</code> performs a <em>pairwise comparison with a baseline</em>. An interval which extends by the given <em>critical difference</em> in both directions is drawn around the <code><a href="../../reference/makeLearner.html">makeLearner()</a></code> chosen as baseline, though only comparisons with the baseline are possible. All learners within the interval are not significantly different, while the baseline can be considered better or worse than a given learner which is outside of the interval.</li>
</ul>
<p>The critical difference <span class="math inline">\(\mathit{CD}\)</span> is calculated by <span class="math display">\[\mathit{CD} = q_\alpha \cdot \sqrt{\frac{k(k+1)}{6N}},\]</span> where <span class="math inline">\(N\)</span> denotes the number of tasks, <span class="math inline">\(k\)</span> is the number of learners, and <span class="math inline">\(q_\alpha\)</span> comes from the studentized range statistic divided by <span class="math inline">\(\sqrt{2}\)</span>. For details see <a href="http://www.jmlr.org/papers/volume7/demsar06a/demsar06a.pdf">Demsar (2006)</a>.</p>
<p>Function <code><a href="../../reference/generateCritDifferencesData.html">generateCritDifferencesData()</a></code> does all necessary calculations while function <code><a href="../../reference/plotCritDifferences.html">plotCritDifferences()</a></code> draws the plot. See the tutorial page about <a href="visualization.html" target="_blank">visualization</a> for details on data generation and plotting functions.</p>
<div class="sourceCode" id="cb28"><html><body><pre class="r"><span class="co"># Nemenyi test</span>
<span class="no">g</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/generateCritDifferencesData.html">generateCritDifferencesData</a></span>(<span class="no">bmr</span>, <span class="kw">p.value</span> <span class="kw">=</span> <span class="fl">0.1</span>, <span class="kw">test</span> <span class="kw">=</span> <span class="st">"nemenyi"</span>)
<span class="fu"><a href="../../reference/plotCritDifferences.html">plotCritDifferences</a></span>(<span class="no">g</span>) + <span class="fu">coord_cartesian</span>(<span class="kw">xlim</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(-<span class="fl">1</span>, <span class="fl">5</span>), <span class="kw">ylim</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0</span>, <span class="fl">2</span>)) +
  <span class="fu">scale_colour_manual</span>(<span class="kw">values</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"lda"</span> <span class="kw">=</span> <span class="st">"#F8766D"</span>, <span class="st">"rpart"</span> <span class="kw">=</span> <span class="st">"#00BA38"</span>, <span class="st">"randomForest"</span> <span class="kw">=</span> <span class="st">"#619CFF"</span>))</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-28-1.png" width="700"></p>
<div class="sourceCode" id="cb29"><html><body><pre class="r">
<span class="co"># Bonferroni-Dunn test</span>
<span class="no">g</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/generateCritDifferencesData.html">generateCritDifferencesData</a></span>(<span class="no">bmr</span>, <span class="kw">p.value</span> <span class="kw">=</span> <span class="fl">0.1</span>, <span class="kw">test</span> <span class="kw">=</span> <span class="st">"bd"</span>, <span class="kw">baseline</span> <span class="kw">=</span> <span class="st">"randomForest"</span>)
<span class="fu"><a href="../../reference/plotCritDifferences.html">plotCritDifferences</a></span>(<span class="no">g</span>) + <span class="fu">coord_cartesian</span>(<span class="kw">xlim</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(-<span class="fl">1</span>, <span class="fl">5</span>), <span class="kw">ylim</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0</span>, <span class="fl">2</span>)) +
  <span class="fu">scale_colour_manual</span>(<span class="kw">values</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"lda"</span> <span class="kw">=</span> <span class="st">"#F8766D"</span>, <span class="st">"rpart"</span> <span class="kw">=</span> <span class="st">"#00BA38"</span>, <span class="st">"randomForest"</span> <span class="kw">=</span> <span class="st">"#619CFF"</span>))</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-28-2.png" width="700"></p>
</div>
<div id="custom-plots" class="section level2">
<h2 class="hasAnchor">
<a href="#custom-plots" class="anchor"></a>Custom plots</h2>
<p>You can easily generate your own visualizations by customizing the <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot2::ggplot()</a></code> objects returned by the plots above, retrieve the data from the <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot2::ggplot()</a></code> objects and use them as basis for your own plots, or rely on the <code><a href="https://rdrr.io/r/base/data.frame.html">base::data.frame()</a></code>s returned by <code><a href="../../reference/getBMRPerformances.html">getBMRPerformances()</a></code> or <code><a href="../../reference/getBMRAggrPerformances.html">getBMRAggrPerformances()</a></code>. Here are some examples.</p>
<p>Instead of boxplots (as in <code><a href="../../reference/plotBMRBoxplots.html">plotBMRBoxplots()</a></code>) we could create density plots to show the performance values resulting from individual resampling iterations.</p>
<div class="sourceCode" id="cb30"><html><body><pre class="r"><span class="no">perf</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span>(<span class="no">bmr</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>)

<span class="co"># Density plots for two tasks</span>
<span class="fu">qplot</span>(<span class="no">mmce</span>, <span class="kw">colour</span> <span class="kw">=</span> <span class="no">learner.id</span>, <span class="kw">facets</span> <span class="kw">=</span> <span class="no">.</span> ~ <span class="no">task.id</span>,
  <span class="kw">data</span> <span class="kw">=</span> <span class="no">perf</span>[<span class="no">perf</span>$<span class="no">task.id</span> <span class="kw">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"iris-example"</span>, <span class="st">"Sonar-example"</span>), ], <span class="kw">geom</span> <span class="kw">=</span> <span class="st">"density"</span>) +
  <span class="fu">theme</span>(<span class="kw">strip.text.x</span> <span class="kw">=</span> <span class="fu">element_text</span>(<span class="kw">size</span> <span class="kw">=</span> <span class="fl">8</span>))</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-29-1.png" width="700"></p>
<p>In order to plot multiple performance measures in parallel, <code>perf</code> is reshaped to long format. Below we generate grouped boxplots showing the error rate and the training time <a href="measures.html" target="_blank">timetrain</a>.</p>
<div class="sourceCode" id="cb31"><html><body><pre class="r"><span class="co"># Compare mmce and timetrain</span>
<span class="no">df</span> <span class="kw">=</span> <span class="kw pkg">reshape2</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/pkg/reshape2/man/melt.html">melt</a></span>(<span class="no">perf</span>, <span class="kw">id.vars</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"task.id"</span>, <span class="st">"learner.id"</span>, <span class="st">"iter"</span>))
<span class="no">df</span> <span class="kw">=</span> <span class="no">df</span>[<span class="no">df</span>$<span class="no">variable</span> <span class="kw">!=</span> <span class="st">"ber"</span>, ]
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">df</span>)
<span class="co">##        task.id learner.id iter variable      value</span>
<span class="co">## 1 iris-example        lda    1     mmce 0.06666667</span>
<span class="co">## 2 iris-example        lda    2     mmce 0.00000000</span>
<span class="co">## 3 iris-example        lda    3     mmce 0.06666667</span>
<span class="co">## 4 iris-example        lda    4     mmce 0.00000000</span>
<span class="co">## 5 iris-example        lda    5     mmce 0.06666667</span>
<span class="co">## 6 iris-example        lda    6     mmce 0.00000000</span>

<span class="fu">qplot</span>(<span class="no">variable</span>, <span class="no">value</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">df</span>, <span class="kw">colour</span> <span class="kw">=</span> <span class="no">learner.id</span>, <span class="kw">geom</span> <span class="kw">=</span> <span class="st">"boxplot"</span>,
  <span class="kw">xlab</span> <span class="kw">=</span> <span class="st">"measure"</span>, <span class="kw">ylab</span> <span class="kw">=</span> <span class="st">"performance"</span>) +
  <span class="fu">facet_wrap</span>(~<span class="no">task.id</span>, <span class="kw">nrow</span> <span class="kw">=</span> <span class="fl">2</span>)</pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-31-1.png" width="700"></p>
<p>It might also be useful to assess if learner performances in single resampling iterations, i.e., in one fold, are related. This might help to gain further insight, for example by having a closer look at train and test sets from iterations where one learner performs exceptionally well while another one is fairly bad. Moreover, this might be useful for the construction of ensembles of learning algorithms. Below, function <code><a href="https://rdrr.io/pkg/GGally/man/ggpairs.html">GGally::ggpairs()</a></code> from package <code>GGally::GGally()</code> is used to generate a scatterplot matrix of <a href="measures.html" target="_blank">mean misclassification errors</a> on the <code><a href="https://rdrr.io/pkg/mlbench/man/Sonar.html">mlbench::Sonar()</a></code> data set.</p>
<div class="sourceCode" id="cb32"><html><body><pre class="r"><span class="no">perf</span> <span class="kw">=</span> <span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span>(<span class="no">bmr</span>, <span class="kw">task.id</span> <span class="kw">=</span> <span class="st">"Sonar-example"</span>, <span class="kw">as.df</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">df</span> <span class="kw">=</span> <span class="kw pkg">reshape2</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/pkg/reshape2/man/melt.html">melt</a></span>(<span class="no">perf</span>, <span class="kw">id.vars</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"task.id"</span>, <span class="st">"learner.id"</span>, <span class="st">"iter"</span>))
<span class="no">df</span> <span class="kw">=</span> <span class="no">df</span>[<span class="no">df</span>$<span class="no">variable</span> <span class="kw">==</span> <span class="st">"mmce"</span>, ]
<span class="no">df</span> <span class="kw">=</span> <span class="kw pkg">reshape2</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/pkg/reshape2/man/cast.html">dcast</a></span>(<span class="no">df</span>, <span class="no">task.id</span> + <span class="no">iter</span> ~ <span class="no">variable</span> + <span class="no">learner.id</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">df</span>)
<span class="co">##         task.id iter  mmce_lda mmce_rpart mmce_randomForest</span>
<span class="co">## 1 Sonar-example    1 0.4285714  0.2380952         0.2380952</span>
<span class="co">## 2 Sonar-example    2 0.1904762  0.2857143         0.0952381</span>
<span class="co">## 3 Sonar-example    3 0.3000000  0.3000000         0.1500000</span>
<span class="co">## 4 Sonar-example    4 0.1904762  0.1904762         0.0000000</span>
<span class="co">## 5 Sonar-example    5 0.3333333  0.4761905         0.2380952</span>
<span class="co">## 6 Sonar-example    6 0.2500000  0.2500000         0.1000000</span>

<span class="kw pkg">GGally</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/pkg/GGally/man/ggpairs.html">ggpairs</a></span>(<span class="no">df</span>, <span class="fl">3</span>:<span class="fl">5</span>)
<span class="co">## Registered S3 method overwritten by 'GGally':</span>
<span class="co">##   method from   </span>
<span class="co">##   +.gg   ggplot2</span></pre></body></html></div>
<p><img src="benchmark_experiments_files/figure-html/unnamed-chunk-32-1.png" width="700"></p>
</div>
</div>
<div id="further-comments" class="section level1">
<h1 class="hasAnchor">
<a href="#further-comments" class="anchor"></a>Further comments</h1>
<ul>
<li>Note that for supervised classification <code>mlr</code> offers some more plots that operate on <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> objects and allow you to compare the performance of learning algorithms. See for example the tutorial page on <a href="roc_analysis.html" target="_blank">ROC analysis</a> and functions <code><a href="../../reference/generateThreshVsPerfData.html">generateThreshVsPerfData()</a></code>, <code><a href="../../reference/plotROCCurves.html">plotROCCurves()</a></code>, and <code>plotViperCharts()</code> as well as the page about <a href="classifier_calibration.html" target="_blank">classifier calibration</a> and function <code><a href="../../reference/generateCalibrationData.html">generateCalibrationData()</a></code>.</li>
<li>In the examples shown in this section we applied “raw” learning algorithms, but often things are more complicated. At the very least, many learners have hyperparameters that need to be tuned to get sensible results. Reliable performance estimates can be obtained by <a href="nested_resampling.html" target="_blank">nested resampling</a>, i.e., by doing the tuning in an inner resampling loop while estimating the performance in an outer loop. Moreover, you might want to combine learners with pre-processing steps like imputation, scaling, outlier removal, dimensionality reduction or feature selection and so on. All this can be easily done using <code>mlr</code>’s wrapper functionality. The general principle is explained in the section about <a href="wrapper.html" target="_blank">wrapper</a> in the Advanced part of this tutorial. There are also several sections devoted to common pre-processing steps.</li>
<li>Benchmark experiments can very quickly become computationally demanding. <code>mlr</code> offers some possibilities for <a href="parallelization.html" target="_blank">parallelization</a>.</li>
</ul>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Patrick Schratz, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.0.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: 'e300ecafdf04fe1199e3339c825ce7d0',
    indexName: 'mlr',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
