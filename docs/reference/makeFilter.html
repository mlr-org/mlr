<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Create a feature filter. — makeFilter • mlr</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  <link href="../extra.css" rel="stylesheet">
  <script src="../extra.js"></script>
<meta property="og:title" content="Create a feature filter. — makeFilter" />

<meta property="og:description" content="Creates and registers custom feature filters. Implemented filters
can be listed with listFilterMethods. Additional
documentation for the fun parameter specific to each filter can
be found in the description.
Minimum redundancy, maximum relevance filter &#8220;mrmr&#8221; computes the
mutual information between the target and each individual feature minus the
average mutual information of previously selected features and this feature
using the mRMRe package.
Filter &#8220;carscore&#8221; determines the &#8220;Correlation-Adjusted (marginal) coRelation
scores&#8221; (short CAR scores). The CAR scores for a set of features are defined as the
correlations between the target and the decorrelated features.
Filter &#8220;randomForestSRC.rfsrc&#8221; computes the importance of random forests
fitted in package randomForestSRC. The concrete method is selected via
the method parameter. Possible values are permute (default), random,
anti, permute.ensemble, random.ensemble, anti.ensemble.
See the VIMP section in the docs for randomForestSRC::rfsrc for
details.
Filter &#8220;randomForestSRC.var.select&#8221; uses the minimal depth variable
selection proposed by Ishwaran et al. (2010) (method = "md") or a
variable hunting approach (method = "vh" or method = "vh.vimp").
The minimal depth measure is the default.
Permutation importance of random forests fitted in package party.
The implementation follows the principle of mean decrese in accuracy used
by the randomForest package (see description of &#8220;randomForest.importance&#8221;)
filter.
Filter &#8220;randomForest.importance&#8221; makes use of the randomForest::importance
from package randomForest. The importance measure to use is selected via
the method parameter:
oob.accuracyPermutation of Out of Bag (OOB) data.
node.impurityTotal decrease in node impurity.
" />

<meta property="og:description" content="The absolute Pearson correlation between each feature and the target is used as an indicator of feature importance.
Missing values are not taken into consideration in a pairwise fashion (see &#8220;pairwise.complete.obs&#8221; in cor).
The absolute Pearson correlation between each feature and the target is used as an indicator of feature importance.
Missing values are not taken into consideration in a pairwise fashion (see &#8220;pairwise.complete.obs&#8221; in cor).
Filter &#8220;information.gain&#8221; uses the entropy-based information gain
between each feature and target individually as an importance measure.
Filter &#8220;gain.ratio&#8221; uses the entropy-based information gain ratio
between each feature and target individually as an importance measure.
Filter &#8220;symmetrical.uncertainty&#8221; uses the entropy-based symmetrical uncertainty
between each feature and target individually as an importance measure.
The chi-square test is a statistical test of independence to determine whether
two variables are independent. Filter &#8220;chi.squared&#8221; applies this
test in the following way. For each feature the chi-square test statistic is
computed checking if there is a dependency between the feature and the target
variable. Low values of the test statistic indicate a poor relationship. High
values, i.e., high dependency identifies a feature as more important.
Filter &#8220;relief&#8221; is based on the feature selection algorithm &#8220;ReliefF&#8221;
by Kononenko et al., which is a generalization of the orignal &#8220;Relief&#8221;
algorithm originally proposed by Kira and Rendell. Feature weights are initialized
with zeros. Then for each instance sample.size instances are sampled,
neighbours.count nearest-hit and nearest-miss neighbours are computed
and the weight vector for each feature is updated based on these values.
Filter &#8220;oneR&#8221; makes use of a simple &#8220;One-Rule&#8221; (OneR) learner to
determine feature importance. For this purpose the OneR learner generates one
simple association rule for each feature in the data individually and computes
the total error. The lower the error value the more important the correspoding
feature.
The &#8220;univariate.model.score&#8221; feature filter resamples an mlr
learner specified via perf.learner for each feature individually
with randomForest from package rpart being the default learner.
Further parameter are the resamling strategey perf.resampling and
the performance measure perf.measure.
Filter &#8220;anova.test&#8221; is based on the Analysis of Variance (ANOVA) between
feature and class. The value of the F-statistic is used as a measure of feature
importance.
Filter &#8220;kruskal.test&#8221; applies a Kruskal-Wallis rank sum test of the
null hypothesis that the location parameters of the distribution of a feature
are the same in each class and considers the test statistic as an variable
importance measure: if the location parameters do not differ in at least one
case, i.e., the null hypothesis cannot be rejected, there is little evidence
that the corresponding feature is suitable for classification.
Simple filter based on the variance of the features indepentent of each other.
Features with higher variance are considered more important than features with
low importance.
Filter &#8220;permutation.importance&#8221; computes a loss function between predictions made by a
learner before and after a feature is permuted. Special arguments to the filter function are
imp.learner, a (Learner or character(1)]) which specifies the learner to use when computing the permutation importance,contrast, afunctionwhich takes two numeric vectors and returns one (default is the difference),aggregation, afunctionwhich takes anumericand returns anumeric(1)(default is the mean),nmc, aninteger(1), andreplace, alogical(1)` which determines whether the feature being
permuted is sampled with or without replacement.
Filter &#8220;auc&#8221; determines for each feature, how well the target
variable can be predicted only based on this feature. More precisely, the
prediction rule is: class 1 if the feature exceeds a threshold and class 0
otherwise. The performance of this classification rule is measured by the
AUC and the resulting filter score is |0.5 - AUC|.
Filter &#8220;ranger.permutation&#8221; trains a ranger learner with
&#8220;importance = "permutation"&#8221; and assesses the variable
importance for each feature.
Filter &#8220;ranger.impurity&#8221; trains a ranger learner with
&#8220;importance = "impurity"&#8221; and assesses the variable
importance for each feature." />

<meta property="og:image" content="https://mlr-org.github.io/mlr/logo.png" />
<meta name="twitter:card" content="summary" />


<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />


<link rel="icon" type="image/png" href="https://mlr-org.github.io/mlr/favicon.ico">
<link rel="apple-touch-icon" type="image/png" href="https://mlr-org.github.io/mlr/favicon.ico">
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../index.html"></a>
      </div>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/mlr.html">Get Started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/task.html">Tasks</a>
    </li>
    <li>
      <a href="../articles/learner.html">Learners</a>
    </li>
    <li>
      <a href="../articles/train.html">Train</a>
    </li>
    <li>
      <a href="../articles/predict.html">Predict</a>
    </li>
    <li>
      <a href="../articles/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../articles/performance.html">Performance</a>
    </li>
    <li>
      <a href="../articles/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../articles/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../articles/benchmark_experiments.html">Benchmark Experiments</a>
    </li>
    <li>
      <a href="../articles/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../articles/visualization.html">Visualization</a>
    </li>
    <li>
      <a href="../articles/usecase_regression.html">Use case - Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/configureMlr.html">Configuration</a>
    </li>
    <li>
      <a href="../articles/wrapper.html">Wrapped Learners</a>
    </li>
    <li>
      <a href="../articles/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../articles/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../articles/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../articles/feature_selection.html">Feature Selection</a>
    </li>
    <li>
      <a href="../articles/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../articles/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../articles/over_and_undersampling.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../articles/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../articles/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../articles/learning_curve.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../articles/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../articles/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../articles/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../articles/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li>
      <a href="../articles/handling_of_spatial_data.html">Handling of Spatial Data</a>
    </li>
    <li>
      <a href="../articles/functional_data.html">Functional Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extending
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/create_learner.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../articles/create_measure.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../articles/create_imputation.html">Create Imputation Methods</a>
    </li>
    <li>
      <a href="../articles/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../reference/index.html">Function Reference</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
    <li>
      <a href="../articles/example_tasks.html">Example Tasks</a>
    </li>
    <li>
      <a href="../articles/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../articles/measures.html">Implemented Measures</a>
    </li>
    <li>
      <a href="../articles/filter_methods.html">Integrated Filter Methods</a>
    </li>
    <li>
      <a href="../articles/mlr_publications.html">mlr Publications</a>
    </li>
    <li>
      <a href="../articles/talks_videos_workshops.html">Talk, Videos and Workshops</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    mlr-org Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://github.com/mlr-org/mlrMBO">mlrMBO</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlrng">mlrng</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlrCPO">mlrCPO</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/shinyMlr">shinyMlr</a>
    </li>
    <li>
      <a href="http://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    </li>
    <li>
      <a href="http://openml.github.io/openml-r/vignettes/OpenML.html">OpenML</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/mlr-org/mlr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.slack.com">
    <span class="fa fa-slack"></span>
     
  </a>
</li>
<li>
  <a href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fa fa-stack-overflow"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.github.io">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
      
      <form class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="search" class="form-control" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
        </div>
      </form>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Create a feature filter.</h1>
    <small>Source: <a href='https://github.com/mlr-org/mlr/blob/master/R/Filter.R'><code>R/Filter.R</code></a></small>
    </div>

    
    <p>Creates and registers custom feature filters. Implemented filters
can be listed with <a href='listFilterMethods.html'>listFilterMethods</a>. Additional
documentation for the <code>fun</code> parameter specific to each filter can
be found in the description.</p>
<p>Minimum redundancy, maximum relevance filter &#8220;mrmr&#8221; computes the
mutual information between the target and each individual feature minus the
average mutual information of previously selected features and this feature
using the <span class="pkg">mRMRe</span> package.</p>
<p>Filter &#8220;carscore&#8221; determines the &#8220;Correlation-Adjusted (marginal) coRelation
scores&#8221; (short CAR scores). The CAR scores for a set of features are defined as the
correlations between the target and the decorrelated features.</p>
<p>Filter &#8220;randomForestSRC.rfsrc&#8221; computes the importance of random forests
fitted in package <span class="pkg">randomForestSRC</span>. The concrete method is selected via
the <code>method</code> parameter. Possible values are <code>permute</code> (default), <code>random</code>,
<code>anti</code>, <code>permute.ensemble</code>, <code>random.ensemble</code>, <code>anti.ensemble</code>.
See the VIMP section in the docs for <a href='http://www.rdocumentation.org/packages/randomForestSRC/topics/rfsrc'>randomForestSRC::rfsrc</a> for
details.</p>
<p>Filter &#8220;randomForestSRC.var.select&#8221; uses the minimal depth variable
selection proposed by Ishwaran et al. (2010) (<code>method = "md"</code>) or a
variable hunting approach (<code>method = "vh"</code> or <code>method = "vh.vimp"</code>).
The minimal depth measure is the default.</p>
<p>Permutation importance of random forests fitted in package <span class="pkg">party</span>.
The implementation follows the principle of mean decrese in accuracy used
by the <span class="pkg">randomForest</span> package (see description of &#8220;randomForest.importance&#8221;)
filter.</p>
<p>Filter &#8220;randomForest.importance&#8221; makes use of the <a href='http://www.rdocumentation.org/packages/randomForest/topics/importance'>randomForest::importance</a>
from package <span class="pkg">randomForest</span>. The importance measure to use is selected via
the <code>method</code> parameter:</p><dl class='dl-horizontal'>
<dt>oob.accuracy</dt><dd><p>Permutation of Out of Bag (OOB) data.</p></dd>
<dt>node.impurity</dt><dd><p>Total decrease in node impurity.</p></dd>
</dl>

    <p>The absolute Pearson correlation between each feature and the target is used as an indicator of feature importance.
Missing values are not taken into consideration in a pairwise fashion (see &#8220;pairwise.complete.obs&#8221; in cor).</p>
<p>The absolute Pearson correlation between each feature and the target is used as an indicator of feature importance.
Missing values are not taken into consideration in a pairwise fashion (see &#8220;pairwise.complete.obs&#8221; in cor).</p>
<p>Filter &#8220;information.gain&#8221; uses the entropy-based information gain
between each feature and target individually as an importance measure.</p>
<p>Filter &#8220;gain.ratio&#8221; uses the entropy-based information gain ratio
between each feature and target individually as an importance measure.</p>
<p>Filter &#8220;symmetrical.uncertainty&#8221; uses the entropy-based symmetrical uncertainty
between each feature and target individually as an importance measure.</p>
<p>The chi-square test is a statistical test of independence to determine whether
two variables are independent. Filter &#8220;chi.squared&#8221; applies this
test in the following way. For each feature the chi-square test statistic is
computed checking if there is a dependency between the feature and the target
variable. Low values of the test statistic indicate a poor relationship. High
values, i.e., high dependency identifies a feature as more important.</p>
<p>Filter &#8220;relief&#8221; is based on the feature selection algorithm &#8220;ReliefF&#8221;
by Kononenko et al., which is a generalization of the orignal &#8220;Relief&#8221;
algorithm originally proposed by Kira and Rendell. Feature weights are initialized
with zeros. Then for each instance <code>sample.size</code> instances are sampled,
<code>neighbours.count</code> nearest-hit and nearest-miss neighbours are computed
and the weight vector for each feature is updated based on these values.</p>
<p>Filter &#8220;oneR&#8221; makes use of a simple &#8220;One-Rule&#8221; (OneR) learner to
determine feature importance. For this purpose the OneR learner generates one
simple association rule for each feature in the data individually and computes
the total error. The lower the error value the more important the correspoding
feature.</p>
<p>The &#8220;univariate.model.score&#8221; feature filter resamples an <span class="pkg">mlr</span>
learner specified via <code>perf.learner</code> for each feature individually
with randomForest from package <span class="pkg">rpart</span> being the default learner.
Further parameter are the resamling strategey <code>perf.resampling</code> and
the performance measure <code>perf.measure</code>.</p>
<p>Filter &#8220;anova.test&#8221; is based on the Analysis of Variance (ANOVA) between
feature and class. The value of the F-statistic is used as a measure of feature
importance.</p>
<p>Filter &#8220;kruskal.test&#8221; applies a Kruskal-Wallis rank sum test of the
null hypothesis that the location parameters of the distribution of a feature
are the same in each class and considers the test statistic as an variable
importance measure: if the location parameters do not differ in at least one
case, i.e., the null hypothesis cannot be rejected, there is little evidence
that the corresponding feature is suitable for classification.</p>
<p>Simple filter based on the variance of the features indepentent of each other.
Features with higher variance are considered more important than features with
low importance.</p>
<p>Filter &#8220;permutation.importance&#8221; computes a loss function between predictions made by a
learner before and after a feature is permuted. Special arguments to the filter function are
<code>imp.learner</code>, a (<a href='makeLearner.html'>Learner</a> or <code>character(1)]) which specifies the learner to use when computing the permutation importance,</code>contrast<code>, a</code>function<code>which takes two numeric vectors and returns one (default is the difference),</code>aggregation<code>, a</code>function<code>which takes a</code>numeric<code>and returns a</code>numeric(1)<code>(default is the mean),</code>nmc<code>, an</code>integer(1)<code>, and</code>replace<code>, a</code>logical(1)` which determines whether the feature being
permuted is sampled with or without replacement.</p>
<p>Filter &#8220;auc&#8221; determines for each feature, how well the target
variable can be predicted only based on this feature. More precisely, the
prediction rule is: class 1 if the feature exceeds a threshold and class 0
otherwise. The performance of this classification rule is measured by the
AUC and the resulting filter score is |0.5 - AUC|.</p>
<p>Filter &#8220;ranger.permutation&#8221; trains a ranger learner with
&#8220;importance = "permutation"&#8221; and assesses the variable
importance for each feature.</p>
<p>Filter &#8220;ranger.impurity&#8221; trains a ranger learner with
&#8220;importance = "impurity"&#8221; and assesses the variable
importance for each feature.</p>
    

    <pre class="usage"><span class='fu'>makeFilter</span>(<span class='no'>name</span>, <span class='no'>desc</span>, <span class='no'>pkg</span>, <span class='no'>supported.tasks</span>, <span class='no'>supported.features</span>, <span class='no'>fun</span>)

<span class='no'>rf.importance</span>

<span class='no'>rf.min.depth</span>

<span class='no'>univariate</span></pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>name</th>
      <td><p>(<code>character(1)</code>)<br />
Identifier for the filter.</p></td>
    </tr>
    <tr>
      <th>desc</th>
      <td><p>(<code>character(1)</code>)<br />
Short description of the filter.</p></td>
    </tr>
    <tr>
      <th>pkg</th>
      <td><p>(<code>character(1)</code>)<br />
Source package where the filter is implemented.</p></td>
    </tr>
    <tr>
      <th>supported.tasks</th>
      <td><p>(character)<br />
Task types supported.</p></td>
    </tr>
    <tr>
      <th>supported.features</th>
      <td><p>(character)<br />
Feature types supported.</p></td>
    </tr>
    <tr>
      <th>fun</th>
      <td><p>(<code>function(task, nselect, ...</code>)<br />
Function which takes a task and returns a named numeric vector of scores,
one score for each feature of <code>task</code>.
Higher scores mean higher importance of the feature.
At least <code>nselect</code> features must be calculated, the remaining may be
set to <code>NA</code> or omitted, and thus will not be selected.
the original order will be restored if necessary.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="format"><a class="anchor" href="#format"></a>Format</h2>

    <p>An object of class <code>Filter</code> of length 6.</p>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>Object of class &#8220;Filter&#8221;.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Kira, Kenji and Rendell, Larry (1992). The Feature Selection Problem: Traditional
Methods and a New Algorithm. AAAI-92 Proceedings.</p>
<p>Kononenko, Igor et al. Overcoming the myopia of inductive learning algorithms
with RELIEFF (1997), Applied Intelligence, 7(1), p39-55.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>Other filter: <code><a href='filterFeatures.html'>filterFeatures</a></code>,
  <code><a href='generateFilterValuesData.html'>generateFilterValuesData</a></code>,
  <code><a href='getFilterValues.html'>getFilterValues</a></code>,
  <code><a href='getFilteredFeatures.html'>getFilteredFeatures</a></code>,
  <code><a href='listFilterMethods.html'>listFilterMethods</a></code>,
  <code><a href='makeFilterWrapper.html'>makeFilterWrapper</a></code>,
  <code><a href='plotFilterValues.html'>plotFilterValues</a></code></p></div>
    

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#format">Format</a></li>

      <li><a href="#value">Value</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
          </ul>

  </div>
</div>

      <footer>
      <!--<div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo, Patrick Schratz.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>
-->
      </footer>
   </div>

   
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript"> docsearch({
 apiKey: 'e300ecafdf04fe1199e3339c825ce7d0',
 indexName: 'mlr',
 inputSelector: 'input#search-input.form-control',
 debug: false // Set debug to true if you want to inspect the dropdown
});
</script>


  </body>
</html>

