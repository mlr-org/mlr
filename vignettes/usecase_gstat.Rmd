---
title: "Use case gstat"
author: "Thomas Goossens (@pokyah)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mlr}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r global_options, echo = FALSE, message = FALSE}
library("sp")
library("gstat")
library("ParamHelpers")
library("dplyr")
library("gridExtra")
devtools::load_all()

## show grouped code output instead of single lines
knitr::opts_chunk$set(collapse = FALSE)
knitr::knit_hooks$set(document = function(x){
  gsub("```\n*```r*\n*", "", x)
})

knitr::opts_chunk$set(warning = FALSE, echo = TRUE, message = FALSE, fig.width = 8, fig.height = 6)
```

For the gstat use case we use the well-known `meuse` and `meuse.grid` datasets from [sp](https://cran.r-project.org/web/packages/sp/index.html) package. 

The purpose of this vignette is to demonstrate how to use gstat spatial prediction functionalities from the mlr interface.

Original gstat code will be presented with its mlr counterpart for various spatial prediction methods (Inverse Distance Weighted, trend surfaces, ordinaray kriging and kriging with external drift).

The examples presented in this vignette are inspired by the examples provided in the gstat [vignette](https://cran.r-project.org/web/packages/gstat/vignettes/gstat.pdf)

First, let's prepare the required libraries

```{r libraries, eval=FALSE}
library(gstat)
library(sp)
library(mlr)
library(dplyr)
```

## Inverse distance Weighted 
Here is the code using pure __gstat__ :
```{r idw_gstat}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# making spatial
coordinates(meuse) = ~x+y
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE
# interpolating
zinc.idw = idw(zinc~1, meuse, meuse.grid)
# mapping
idw.gstat.plot = spplot(zinc.idw["var1.pred"], do.log = F, colorkey = TRUE,  main = "zn : idw interpoaltion (gstat)")
```

And using __mlr__ : 
```{r idw_mlr}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# defining the regression task
task = makeRegrTask(id = "meuse",  data = meuse, target = "zinc")
task.idw = dropFeatures(task = task, features = getTaskFeatureNames(task)[-c(1,2)])
# defining the learner
lrn.idw = makeLearner(cl = "regr.gstat", id = "mlr-idw", locations = ~x+y)
# training the model
mod.idw = train(lrn.idw, task.idw)
# interpolating
newdata.pred.idw = predict(mod.idw, newdata = meuse.grid)
mlr.idw = bind_cols(data.frame(meuse.grid), newdata.pred.idw$data)
# mapping
coordinates(mlr.idw) = ~x+y
gridded(mlr.idw) = TRUE
idw.mlr.plot = spplot(mlr.idw["response"], do.log = F, colorkey = TRUE, main = "zn : idw interpoaltion (mlr)")
```

Let's check that spatial predictions outputs are identical for the 2 methods :

```{r idw_maps, echo=FALSE, fig.height=3}
do.call(gridExtra::grid.arrange, (list(idw.gstat.plot, idw.mlr.plot, ncol = 2)))
```

```{r idw_identical}
identical(zinc.idw["var1.pred"]@data[[1]], mlr.idw["response"]@data[[1]])
```

## Trend surfaces interpolation.
Here is the code using pure __gstat__ :

```{r ts_gstat}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data (using mlr::imput)
meuse = mlr::impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = mlr::impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# making spatial
sp::coordinates(meuse) = ~x+y
sp::coordinates(meuse.grid) = ~x+y
sp::gridded(meuse.grid) = TRUE
# interpolating
ts.gstat = meuse.grid
ts.gstat$ts1 = krige(log(zinc) ~ 1, meuse, meuse.grid, degree = 1)$var1.pred
ts.gstat$ts2 = krige(log(zinc) ~ 1, meuse, meuse.grid, degree = 2)$var1.pred
ts.gstat$ts3 = krige(log(zinc) ~ 1, meuse, meuse.grid, degree = 3)$var1.pred
# mapping
ts.gstat.plot = spplot(ts.gstat, c("ts1", "ts2", "ts3"), main = "log(zn) : ts interpolation (gstat)")
```

And using __mlr__ : 

```{r ts_mlr}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# adding a column with log zinc
meuse = meuse %>% dplyr::mutate(log_zinc = log(zinc))
# defining the regression task
task = makeRegrTask(id = "meuse",  data = meuse, target = "log_zinc")
task.ts = dropFeatures(task = task, features = getTaskFeatureNames(task)[-c(1,2)])
# defining the learner
lrn.ts.1 = makeLearner(cl = "regr.gstat", id = "mlr-ts1", degree = 1, locations = ~x+y)
lrn.ts.2 = makeLearner(cl = "regr.gstat", id = "mlr-ts2", degree = 2, locations = ~x+y)
lrn.ts.3 = makeLearner(cl = "regr.gstat", id = "mlr-ts3", degree = 3, locations = ~x+y)
# training the learners
mod.ts.1 = train(lrn.ts.1, task.ts)
mod.ts.2 = train(lrn.ts.2, task.ts)
mod.ts.3 = train(lrn.ts.3, task.ts)
# interpolating
ts.mlr = meuse.grid
newdata.pred.ts.1 = predict(mod.ts.1, newdata = meuse.grid)
ts.mlr$mlr.ts.1 = (bind_cols(data.frame(meuse.grid), newdata.pred.ts.1$data))$response
newdata.pred.ts.2 = predict(mod.ts.2, newdata = meuse.grid)
ts.mlr$mlr.ts.2 = (bind_cols(data.frame(meuse.grid), newdata.pred.ts.2$data))$response
newdata.pred.ts.3 = predict(mod.ts.3, newdata = meuse.grid)
ts.mlr$mlr.ts.3 = (bind_cols(data.frame(meuse.grid), newdata.pred.ts.3$data))$response
# mapping
coordinates(ts.mlr) = ~x+y
gridded(ts.mlr) = TRUE
ts.mlr.plot = spplot(ts.mlr, c("mlr.ts.1", "mlr.ts.2", "mlr.ts.3"), main = "log(zn) : ts interpolation (mlr)")
```

Let's check that spatial predictions outputs are identical for the 2 methods :

```{r ts_maps, echo=FALSE}
do.call(gridExtra::grid.arrange, (list(ts.gstat.plot, ts.mlr.plot)))
```

```{r ts_identical}
identical(ts.mlr$mlr.ts.1, ts.gstat$ts1)
identical(ts.mlr$mlr.ts.2, ts.gstat$ts2)
identical(ts.mlr$mlr.ts.3, ts.gstat$ts3)
```

## Ordinary kriging example
Here is the code using pure __gstat__
```{r ok_gstat}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# making spatial
coordinates(meuse) = ~x+y
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE
# computing sample variogram
lzn.vgm = variogram(log(zinc)~1, meuse)
# manually fitting a model to the vgm with constant mean
lzn.fit = fit.variogram(lzn.vgm, model = vgm(1, "Sph", 900, 1))
# to show the plot run : plot(lzn.vgm, lzn.fit)
# kriging
ok.gstat = krige(log(zinc)~1, meuse, meuse.grid, model = lzn.fit)
# mapping
ok.gstat.plot = spplot(ok.gstat["var1.pred"], do.log = F, colorkey = TRUE, main = "log(zn) : ok interpolation (gstat)")
# mapping the se
ok.se.gstat.plot = spplot(ok.gstat["var1.var"], do.log = F, colorkey = TRUE, main = "se(log(zn)) : ok interpolation (gstat)")
```

And using __mlr__
```{r ok_mlr}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# adding a column with log zinc
meuse = meuse %>% dplyr::mutate(log_zinc = log(zinc))
# defining the regression task
task = makeRegrTask(id = "meuse",  data = meuse, target = "log_zinc")
task.krg = dropFeatures(task = task, features = getTaskFeatureNames(task)[-c(1,2)])
# defining the learner
lrn.krg = makeLearner(cl = "regr.gstat", id = "ln(zn) mlr ordinary kriging", predict.type = "response", psill = 1, model = "Sph", range = 900, nugget = 1, locations = ~x+y)
# training the model
mod.krg = train(lrn.krg, task.krg)
# kriging
newdata.pred.krg = predict(object = mod.krg, newdata = meuse.grid)
ok.mlr = bind_cols(data.frame(meuse.grid), newdata.pred.krg$data)
# mapping
coordinates(ok.mlr) = ~x+y
gridded(ok.mlr) = TRUE
ok.mlr.plot = spplot(ok.mlr["response"], do.log = T, colorkey = TRUE, main = "log(zn) : ok interpolation (gstat)")
# SE - defining the standard error learner by altering the previous one.
se.lrn.krg = setPredictType(lrn.krg, predict.type = "se")
# training the SE model
se.mod.krg = train(se.lrn.krg, task.krg)
# SE kriging
se.newdata.pred.krg = predict(object = se.mod.krg, newdata = meuse.grid)
ok.se.mlr = bind_cols(data.frame(meuse.grid), se.newdata.pred.krg$data)
# SE mapping
coordinates(ok.se.mlr) = ~x+y
gridded(ok.se.mlr) = TRUE
ok.se.mlr.plot = spplot(ok.se.mlr["se"], do.log = T, colorkey = TRUE, main = "se(log(zn)) : ok interpolation (mlr)")
```

Let's check that spatial predictions outputs are identical for the 2 methods :

```{r ok_maps, echo=FALSE}
do.call(gridExtra::grid.arrange, (list(ok.gstat.plot, ok.mlr.plot, ok.se.gstat.plot, ok.se.mlr.plot)))
```

```{r ok_identical}
identical(ok.gstat["var1.pred"]@data[[1]], ok.mlr["response"]@data[[1]])
```

## Kriging with External Drift (KED) = Universal Kriging (UK)

Using __gstat__ 

```{r ked_gstat}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# making spatial
coordinates(meuse) = ~x+y
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE
# computing sample variogram
lzn.vgm = variogram(log(zinc)~1, meuse)
# manually fitting a model to the vgm with a mean function where sqrt dist is the explanatory var
lzn.vgm = variogram(log(zinc)~sqrt(dist), meuse)
lzn.fit = fit.variogram(lzn.vgm, model = vgm(1, "Exp", 300, 1))
# to show the plot run : plot(lzn.vgm, lzn.fit)
# kriging
ked.gstat = krige(log(zinc)~sqrt(dist), meuse, meuse.grid, model = lzn.fit)
# mapping
ked.gstat.plot = spplot(ked.gstat["var1.pred"], do.log = F, colorkey = TRUE, main = "log(zn) : ked interpolation (gstat)")
# mapping the se
ked.se.gstat.plot = spplot(ked.gstat["var1.var"], do.log = F, colorkey = TRUE, main = "se(log(zn)) : ked interpolation (gstat)")
```

And using __mlr__
```{r ked_mlr}
# loading datasets
data(meuse)
data(meuse.grid)
# imputing values to missing data
meuse = impute(meuse, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
meuse.grid = impute(meuse.grid, classes = list(numeric = imputeMean(), factor = imputeMode()),
  dummy.classes = "integer")$data
# adding a column with log zinc
meuse = meuse %>% dplyr::mutate(log_zinc = log(zinc))
# adding a column with sqrt dist
meuse = meuse %>% dplyr::mutate(sqrt_dist = sqrt(dist))
meuse.grid = meuse.grid %>% dplyr::mutate(sqrt_dist = sqrt(dist))
# defining the regression task
task = makeRegrTask(id = "meuse",  data = meuse, target = "log_zinc")
task.krg = dropFeatures(task = task, features = getTaskFeatureNames(task)[-c(1,2,15)])
# defining the learner
lrn.krg = makeLearner(cl = "regr.gstat", id = "ln(zn) mlr kriging with external drift", predict.type = "response",  psill = 1, model = "Exp", range = 300, nugget = 1, locations = ~x+y) 
# training the model
mod.krg = train(lrn.krg, task.krg)
# kriging
newdata.pred.krg = predict(object = mod.krg, newdata = meuse.grid)
ked.mlr = bind_cols(data.frame(meuse.grid), newdata.pred.krg$data)
# mapping
coordinates(ked.mlr) = ~x+y
gridded(ked.mlr) = TRUE
ked.mlr.plot = spplot(ked.mlr["response"], do.log = T, colorkey = TRUE, main = "log(zn) : ked interpolation (mlr)")
# SE - defining the standard error learner by altering the previous one.
se.lrn.krg = setPredictType(lrn.krg, predict.type = "se")
# training the SE model
se.mod.krg = train(se.lrn.krg, task.krg)
# SE kriging
se.newdata.pred.krg = predict(object = se.mod.krg, newdata = meuse.grid)
ked.se.mlr = bind_cols(data.frame(meuse.grid), se.newdata.pred.krg$data)
# SE mapping
coordinates(ked.se.mlr) = ~x+y
gridded(ked.se.mlr) = TRUE
ked.se.mlr.plot = spplot(ked.se.mlr["se"], do.log = T, colorkey = TRUE, main = "se(log(zn)) : ked interpolation (mlr)")
```

Let's check that spatial predictions outputs are identical for the 2 methods :

```{r ked_maps, echo=FALSE}
do.call(gridExtra::grid.arrange, (list(ked.gstat.plot, ked.mlr.plot, ked.se.gstat.plot, ked.se.mlr.plot)))
```

```{r ked_identical}
identical(ked.gstat["var1.pred"]@data[[1]], ked.mlr["response"]@data[[1]])
```

