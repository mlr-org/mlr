<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">



        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Resampling - mlr tutorial</title>
        <link href="css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="css/highlight.css">
        <link href="css/custom_mlr.css" rel="stylesheet">
        <link href="css/custom_highlight.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

	<script src="js/jquery-1.10.2.min.js"></script>
        <script src="js/bootstrap-3.0.3.min.js"></script>
        <script src="js/highlight.pack.js"></script>
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">mlr tutorial</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="index.html">Home</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Basics <b class="caret"></b></a>
                        <ul class="dropdown-menu">

<li >
    <a href="task.html">Tasks</a>
</li>

<li >
    <a href="learner.html">Learners</a>
</li>

<li >
    <a href="train.html">Train</a>
</li>

<li >
    <a href="predict.html">Predict</a>
</li>

<li >
    <a href="performance.html">Performance</a>
</li>

<li >
    <a href="resample.html">Resampling</a>
</li>

<li >
    <a href="tune.html">Tuning</a>
</li>

<li >
    <a href="benchmark_experiments.html">Benchmark Experiments</a>
</li>

<li >
    <a href="parallelization.html">Parallelization</a>
</li>

<li >
    <a href="visualization.html">Visualization</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Advanced <b class="caret"></b></a>
                        <ul class="dropdown-menu">

<li >
    <a href="configureMlr.html">Configuration</a>
</li>

<li >
    <a href="wrapper.html">Wrapped Learners</a>
</li>

<li >
    <a href="preproc.html">Preprocessing</a>
</li>

<li >
    <a href="impute.html">Imputation</a>
</li>

<li class="active">
    <a href="bagging.html">Bagging</a>
</li>

<li >
    <a href="advanced_tune.html">Advanced Tuning</a>
</li>

<li >
    <a href="feature_selection.html">Feature Selection</a>
</li>

<li >
    <a href="nested_resampling.html">Nested Resampling</a>
</li>

<li >
    <a href="cost_sensitive_classif.html">Cost-Sensitive Classification</a>
</li>

<li >
    <a href="over_and_undersampling.html">Imbalanced Classification Problems</a>
</li>

<li >
    <a href="roc_analysis.html">ROC Analysis</a>
</li>

<li >
    <a href="multilabel.html">Multilabel Classification</a>
</li>

<li >
    <a href="learning_curve.html">Learning Curves</a>
</li>

<li >
    <a href="partial_dependence.html">Partial Dependence Plots</a>
</li>

<li >
    <a href="classifier_calibration.html">Classifier Calibration Plots</a>
</li>

<li >
    <a href="hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
</li>

<li >
    <a href="out_of_bag_predictions.html">Out-of-Bag Predictions</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Extend <b class="caret"></b></a>
                        <ul class="dropdown-menu">

<li >
    <a href="create_learner.html">Create Custom Learners</a>
</li>

<li >
    <a href="create_measure.html">Create Custom Measures</a>
</li>

<li >
    <a href="create_imputation.html">Create Imputation Methods</a>
</li>

<li >
    <a href="create_filter.html">Create Custom Filters</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Appendix <b class="caret"></b></a>
                        <ul class="dropdown-menu">

<li >
    <a href="example_tasks.html">Example Tasks</a>
</li>

<li >
    <a href="integrated_learners.html">Integrated Learners</a>
</li>

<li >
    <a href="measures.html">Implemented Performance Measures</a>
</li>

<li >
    <a href="filter_methods.html">Integrated Filter Methods</a>
</li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../performance/index.html">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../tune/index.html">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/mlr-org/mlr/">
                                <i class="fa fa-github"></i>GitHub
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#resampling">Resampling</a></li>
            <li><a href="#defining-the-resampling-strategy">Defining the resampling strategy</a></li>
            <li><a href="#performing-the-resampling">Performing the resampling</a></li>
            <li><a href="#accessing-resample-results">Accessing resample results</a></li>
            <li><a href="#stratification-and-blocking">Stratification and blocking</a></li>
            <li><a href="#resample-descriptions-and-resample-instances">Resample descriptions and resample instances</a></li>
            <li><a href="#aggregating-performance-values">Aggregating performance values</a></li>
            <li><a href="#convenience-functions">Convenience functions</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="resampling">Resampling</h1>
<p>Resampling strategies are usually used to assess the performance of a learning algorithm:
The entire data set is (repeatedly) split into training sets <script type="math/tex">D^{*b}</script> and test sets
<script type="math/tex">D \setminus D^{*b}</script>, <script type="math/tex">b = 1,\ldots,B</script>.
The learner is trained on each training set, predictions are made on the corresponding test
set (sometimes on the training set as well) and the performance measure
<script type="math/tex">S(D^{*b}, D \setminus D^{*b})</script> is calculated.
Then the <script type="math/tex">B</script> individual performance values are aggregated, most often by calculating the mean.
There exist various different resampling strategies, for example cross-validation and bootstrap,
to mention just two popular approaches.</p>
<p><img alt="Resampling Figure" src="../img/resampling.png" title="Resampling Figure" /></p>
<p>If you want to read up on further details, the paper
<a href="http://link.springer.com/chapter/10.1007%2F978-0-387-47509-7_8">Resampling Strategies for Model Assessment and Selection</a>
by Simon is probably not a bad choice.
Bernd has also published a paper
<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/EVCO_a_00069">Resampling methods for meta-model validation with recommendations for evolutionary computation</a>
which contains detailed descriptions and lots of statistical background information on resampling methods.</p>
<h2 id="defining-the-resampling-strategy">Defining the resampling strategy</h2>
<p>In <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> the resampling strategy can be defined via function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>.
It requires a string that specifies the resampling method and, depending on the selected
strategy, further information like the number of iterations.
The supported resampling strategies are:</p>
<ul>
<li>Cross-validation (<code>"CV"</code>),</li>
<li>Leave-one-out cross-validation (<code>"LOO"</code>),</li>
<li>Repeated cross-validation (<code>"RepCV"</code>),</li>
<li>Out-of-bag bootstrap and other variants like <em>b632</em> (<code>"Bootstrap"</code>),</li>
<li>Subsampling, also called Monte-Carlo cross-validation (<code>"Subsample"</code>),</li>
<li>Holdout (training/test) (<code>"Holdout"</code>).</li>
</ul>
<p>For example if you want to use 3-fold cross-validation type:</p>
<pre><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
rdesc
#&gt; Resample description: cross-validation with 3 iterations.
#&gt; Predict: test
#&gt; Stratification: FALSE
</code></pre>

<p>For holdout estimation use:</p>
<pre><code class="r">## Holdout estimation
rdesc = makeResampleDesc(&quot;Holdout&quot;)
rdesc
#&gt; Resample description: holdout with 0.67 split rate.
#&gt; Predict: test
#&gt; Stratification: FALSE
</code></pre>

<p>In order to save you some typing <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> contains some pre-defined resample descriptions for
very common strategies like holdout (<a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">hout</a>) as well as cross-validation
with different numbers of folds (e.g., <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">cv5</a> or <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">cv10</a>).</p>
<pre><code class="r">hout
#&gt; Resample description: holdout with 0.67 split rate.
#&gt; Predict: test
#&gt; Stratification: FALSE

cv3
#&gt; Resample description: cross-validation with 3 iterations.
#&gt; Predict: test
#&gt; Stratification: FALSE
</code></pre>

<h2 id="performing-the-resampling">Performing the resampling</h2>
<p>Function <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> evaluates a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> on a
given machine learning <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a> using the selected <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">resampling strategy</a>.</p>
<p>As a first example, the performance of <a href="http://www.rdocumentation.org/packages/stats/functions/lm.html">linear regression</a> on the
<a href="http://www.rdocumentation.org/packages/mlbench/functions/BostonHousing.html">BostonHousing</a> data set is calculated using <em>3-fold cross-validation</em>.</p>
<p>Generally, for <em><script type="math/tex">K</script>-fold cross-validation</em> the data set <script type="math/tex">D</script> is partitioned into <script type="math/tex">K</script> subsets
of (approximately) equal size.
In the <script type="math/tex">b</script>-th of the <script type="math/tex">K</script> iterations, the <script type="math/tex">b</script>-th subset is used for testing, while the union
of the remaining parts forms the training set.</p>
<p>As usual, you can either pass a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> object to <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> or, as done here,
provide the class name <code>"regr.lm"</code> of the learner.
Since no performance measure is specified the default for regression learners
(mean squared error, <a href="../measures/index.html">mse</a>) is calculated.</p>
<pre><code class="r">## Specify the resampling strategy (3-fold cross-validation)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)

## Calculate the performance
r = resample(&quot;regr.lm&quot;, bh.task, rdesc)
#&gt; [Resample] cross-validation iter 1:
#&gt; mse.test.mean=19.9
#&gt; [Resample] cross-validation iter 2:
#&gt; mse.test.mean=31.8
#&gt; [Resample] cross-validation iter 3:
#&gt; mse.test.mean=  21
#&gt; [Resample] Aggr. Result: mse.test.mean=24.2

r
#&gt; Resample Result
#&gt; Task: BostonHousing-example
#&gt; Learner: regr.lm
#&gt; Aggr perf: mse.test.mean=24.2
#&gt; Runtime: 0.0765951
</code></pre>

<p>The result <code>r</code> is an object of class <a href="http://www.rdocumentation.org/packages/mlr/functions/ResampleResult.html">ResampleResult</a>.
It contains performance results for the learner and some additional information
like the runtime, predicted values, and optionally the models fitted in single resampling
iterations.</p>
<pre><code class="r">## Peak into r
names(r)
#&gt;  [1] &quot;learner.id&quot;     &quot;task.id&quot;        &quot;task.desc&quot;      &quot;measures.train&quot;
#&gt;  [5] &quot;measures.test&quot;  &quot;aggr&quot;           &quot;pred&quot;           &quot;models&quot;
#&gt;  [9] &quot;err.msgs&quot;       &quot;err.dumps&quot;      &quot;extract&quot;        &quot;runtime&quot;

r$aggr
#&gt; mse.test.mean
#&gt;      24.21616

r$measures.test
#&gt;   iter      mse
#&gt; 1    1 19.89828
#&gt; 2    2 31.78034
#&gt; 3    3 20.96985
</code></pre>

<p><code>r$measures.test</code> gives the performance on each of the 3 test data sets.
<code>r$aggr</code> shows the aggregated performance value.
Its name <code>"mse.test.mean"</code> indicates the performance measure, <a href="../measures/index.html">mse</a>,
and the method, <a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.mean</a>, used to aggregate the 3 individual performances.
<a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.mean</a> is the default aggregation scheme for most performance measures
and, as the name implies, takes the mean over the performances on the test data sets.</p>
<p>Resampling in <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> works the same way for all types of learning problems and learners.
Below is a classification example where a <a href="http://www.rdocumentation.org/packages/rpart/functions/rpart.html">classification tree (rpart)</a> is
evaluated on the <a href="http://www.rdocumentation.org/packages/mlbench/functions/sonar.html">Sonar</a> data set by subsampling with 5 iterations.</p>
<p>In each subsampling iteration the data set <script type="math/tex">D</script> is randomly partitioned into a
training and a test set according to a given percentage, e.g., 2/3
training and 1/3 test set. If there is just one iteration, the strategy
is commonly called <em>holdout</em> or <em>test sample estimation</em>.</p>
<p>You can calculate several measures at once by passing a <a href="http://www.rdocumentation.org/packages/base/functions/list.html">list</a> of
<a href="http://www.rdocumentation.org/packages/mlr/functions/makeMeasure.html">Measure</a>s to <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>.
Below, the error rate (<a href="../measures/index.html">mmce</a>), false positive and false negative rates
(<a href="../measures/index.html">fpr</a>, <a href="../measures/index.html">fnr</a>), and the time it takes to train the learner
(<a href="../measures/index.html">timetrain</a>) are estimated by <em>subsampling</em> with 5 iterations.</p>
<pre><code class="r">## Subsampling with 5 iterations and default split ratio 2/3
rdesc = makeResampleDesc(&quot;Subsample&quot;, iters = 5)

## Subsampling with 5 iterations and 4/5 training data
rdesc = makeResampleDesc(&quot;Subsample&quot;, iters = 5, split = 4/5)

## Classification tree with information splitting criterion
lrn = makeLearner(&quot;classif.rpart&quot;, parms = list(split = &quot;information&quot;))

## Calculate the performance measures
r = resample(lrn, sonar.task, rdesc, measures = list(mmce, fpr, fnr, timetrain))
#&gt; [Resample] subsampling iter 1:
#&gt; mmce.test.mean=0.262,fpr.test.mean=0.235,fnr.test.mean=0.28,timetrain.test.mean=0.033
#&gt; [Resample] subsampling iter 2:
#&gt; mmce.test.mean=0.286,fpr.test.mean=0.286,fnr.test.mean=0.286,timetrain.test.mean=0.034
#&gt; [Resample] subsampling iter 3:
#&gt; mmce.test.mean=0.262,fpr.test.mean=0.286,fnr.test.mean=0.238,timetrain.test.mean=0.046
#&gt; [Resample] subsampling iter 4:
#&gt; mmce.test.mean=0.333,fpr.test.mean=0.35,fnr.test.mean=0.318,timetrain.test.mean=0.03
#&gt; [Resample] subsampling iter 5:
#&gt; mmce.test.mean=0.333,fpr.test.mean=0.167,fnr.test.mean=0.458,timetrain.test.mean=0.027
#&gt; [Resample] Aggr. Result: mmce.test.mean=0.295,fpr.test.mean=0.265,fnr.test.mean=0.316,timetrain.test.mean=0.034

r
#&gt; Resample Result
#&gt; Task: Sonar-example
#&gt; Learner: classif.rpart
#&gt; Aggr perf: mmce.test.mean=0.295,fpr.test.mean=0.265,fnr.test.mean=0.316,timetrain.test.mean=0.034
#&gt; Runtime: 0.338189
</code></pre>

<p>If you want to add further measures afterwards, use <a href="http://www.rdocumentation.org/packages/mlr/functions/addRRMeasure.html">addRRMeasure</a>.</p>
<pre><code class="r">## Add balanced error rate (ber) and time used to predict
addRRMeasure(r, list(ber, timepredict))
#&gt; Resample Result
#&gt; Task: Sonar-example
#&gt; Learner: classif.rpart
#&gt; Aggr perf: mmce.test.mean=0.295,fpr.test.mean=0.265,fnr.test.mean=0.316,timetrain.test.mean=0.034,ber.test.mean=0.29,timepredict.test.mean=0.0138
#&gt; Runtime: 0.338189
</code></pre>

<p>By default, <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> prints progress messages and intermediate results. You can turn this off by setting
<code>show.info = FALSE</code>, as done in the code chunk below. (If you are interested in suppressing
these messages permanently have a look at the tutorial page about <a href="../configureMlr/index.html">configuring mlr</a>.)</p>
<p>In the above example, the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> was explicitly constructed. For convenience
you can also specify the learner as a string and pass any learner parameters via the <code>...</code> argument
of <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>.</p>
<pre><code class="r">r = resample(&quot;classif.rpart&quot;, parms = list(split = &quot;information&quot;), sonar.task, rdesc,
  measures = list(mmce, fpr, fnr, timetrain), show.info = FALSE)

r
#&gt; Resample Result
#&gt; Task: Sonar-example
#&gt; Learner: classif.rpart
#&gt; Aggr perf: mmce.test.mean=0.305,fpr.test.mean=0.279,fnr.test.mean=0.309,timetrain.test.mean=0.0348
#&gt; Runtime: 0.326192
</code></pre>

<h2 id="accessing-resample-results">Accessing resample results</h2>
<p>Apart from the learner performance you can extract further information from the
resample results, for example predicted values or the models fitted in individual resample
iterations.</p>
<h3 id="predictions">Predictions</h3>
<p>Per default, the <a href="http://www.rdocumentation.org/packages/mlr/functions/ResampleResult.html">ResampleResult</a> contains the predictions made during the resampling.
If you do not want to keep them, e.g., in order to conserve memory,
set <code>keep.pred = FALSE</code> when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>.</p>
<p>The predictions are stored in slot <code>$pred</code> of the resampling result, which can also be accessed
by function <a href="http://www.rdocumentation.org/packages/mlr/functions/getRRPredictions.html">getRRPredictions</a>.</p>
<pre><code class="r">r$pred
#&gt; Resampled Prediction for:
#&gt; Resample description: subsampling with 5 iterations and 0.80 split rate.
#&gt; Predict: test
#&gt; Stratification: FALSE
#&gt; predict.type: response
#&gt; threshold:
#&gt; time (mean): 0.01
#&gt;    id truth response iter  set
#&gt; 1  36     R        M    1 test
#&gt; 2 132     M        R    1 test
#&gt; 3 145     M        R    1 test
#&gt; 4 161     M        R    1 test
#&gt; 5 108     M        M    1 test
#&gt; 6 178     M        M    1 test
#&gt; ... (210 rows, 5 cols)

pred = getRRPredictions(r)
pred
#&gt; Resampled Prediction for:
#&gt; Resample description: subsampling with 5 iterations and 0.80 split rate.
#&gt; Predict: test
#&gt; Stratification: FALSE
#&gt; predict.type: response
#&gt; threshold:
#&gt; time (mean): 0.01
#&gt;    id truth response iter  set
#&gt; 1  36     R        M    1 test
#&gt; 2 132     M        R    1 test
#&gt; 3 145     M        R    1 test
#&gt; 4 161     M        R    1 test
#&gt; 5 108     M        M    1 test
#&gt; 6 178     M        M    1 test
#&gt; ... (210 rows, 5 cols)
</code></pre>

<p><code>pred</code> is an object of class <a href="http://www.rdocumentation.org/packages/mlr/functions/ResamplePrediction.html">ResamplePrediction</a>.
Just as a <a href="http://www.rdocumentation.org/packages/mlr/functions/Prediction.html">Prediction</a> object (see the tutorial page on <a href="../predict/index.html">making predictions</a>)
it has an element <code>$data</code> which is a <a href="http://www.rdocumentation.org/packages/base/functions/data.frame.html">data.frame</a> that contains the
predictions and in the case of a supervised learning problem the true values of the target
variable(s).
You can use <a href="http://www.rdocumentation.org/packages/mlr/functions/Prediction.html">as.data.frame</a> to directly access the <code>$data</code> slot. Moreover, all getter
functions for <a href="http://www.rdocumentation.org/packages/mlr/functions/Prediction.html">Prediction</a> objects like <a href="http://www.rdocumentation.org/packages/mlr/functions/getPredictionResponse.html">getPredictionResponse</a> or
<a href="http://www.rdocumentation.org/packages/mlr/functions/getPredictionProbabilities.html">getPredictionProbabilities</a> are applicable.</p>
<pre><code class="r">head(as.data.frame(pred))
#&gt;    id truth response iter  set
#&gt; 1  36     R        M    1 test
#&gt; 2 132     M        R    1 test
#&gt; 3 145     M        R    1 test
#&gt; 4 161     M        R    1 test
#&gt; 5 108     M        M    1 test
#&gt; 6 178     M        M    1 test

head(getPredictionTruth(pred))
#&gt; [1] R M M M M M
#&gt; Levels: M R

head(getPredictionResponse(pred))
#&gt; [1] M R R R M M
#&gt; Levels: M R
</code></pre>

<p>The columns <code>iter</code> and <code>set</code> in the <a href="http://www.rdocumentation.org/packages/base/functions/data.frame.html">data.frame</a> indicate the
resampling iteration and the data set (<code>train</code> or <code>test</code>) for which the prediction was made.</p>
<p>By default, predictions are made for the test sets only.
If predictions for the training set are required, set <code>predict = "train"</code> (for predictions
on the train set only) or <code>predict = "both"</code> (for predictions on both train and test sets)
in <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>. In any case, this is necessary for some bootstrap methods
(<em>b632</em> and <em>b632+</em>) and some examples are shown <a href="../resample#aggregating-performance-values">later on</a>.</p>
<p>Below, we use simple Holdout, i.e., split the data once into a training and test set, as
resampling strategy and make predictions on both sets.</p>
<pre><code class="r">## Make predictions on both training and test sets
rdesc = makeResampleDesc(&quot;Holdout&quot;, predict = &quot;both&quot;)

r = resample(&quot;classif.lda&quot;, iris.task, rdesc, show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: iris-example
#&gt; Learner: classif.lda
#&gt; Aggr perf: mmce.test.mean=0.02
#&gt; Runtime: 0.0594802

r$measures.train
#&gt;   iter mmce
#&gt; 1    1 0.02
</code></pre>

<p>(Please note that nonetheless the misclassification rate <code>r$aggr</code> is estimated on the test data only.
How to calculate performance measures on the training sets is shown
<a href="../resample#aggregating-performance-values">below</a>.)</p>
<p>A second function to extract predictions from resample results is <a href="http://www.rdocumentation.org/packages/mlr/functions/getRRPredictionList.html">getRRPredictionList</a>
which returns a <a href="http://www.rdocumentation.org/packages/base/functions/list.html">list</a> of predictions split by data set (train/test) and
resampling iteration.</p>
<pre><code class="r">predList = getRRPredictionList(r)
predList
#&gt; $train
#&gt; $train$`1`
#&gt; Prediction: 100 observations
#&gt; predict.type: response
#&gt; threshold:
#&gt; time: 0.00
#&gt;      id      truth   response
#&gt; 123 123  virginica  virginica
#&gt; 101 101  virginica  virginica
#&gt; 51   51 versicolor versicolor
#&gt; 45   45     setosa     setosa
#&gt; 46   46     setosa     setosa
#&gt; 3     3     setosa     setosa
#&gt; ... (100 rows, 3 cols)
#&gt;
#&gt;
#&gt;
#&gt; $test
#&gt; $test$`1`
#&gt; Prediction: 50 observations
#&gt; predict.type: response
#&gt; threshold:
#&gt; time: 0.00
#&gt;      id      truth   response
#&gt; 109 109  virginica  virginica
#&gt; 80   80 versicolor versicolor
#&gt; 40   40     setosa     setosa
#&gt; 140 140  virginica  virginica
#&gt; 125 125  virginica  virginica
#&gt; 10   10     setosa     setosa
#&gt; ... (50 rows, 3 cols)
</code></pre>

<h3 id="learner-models">Learner models</h3>
<p>In each resampling iteration a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> is fitted on the respective training set.
By default, the resulting <a href="http://www.rdocumentation.org/packages/mlr/functions/makeWrappedModel.html">WrappedModel</a>s are not included in the
<a href="http://www.rdocumentation.org/packages/mlr/functions/ResampleResult.html">ResampleResult</a> and slot <code>$models</code> is empty.
In order to keep them, set <code>models = TRUE</code> when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>, as in the following
survival analysis example.</p>
<pre><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)

r = resample(&quot;surv.coxph&quot;, lung.task, rdesc, show.info = FALSE, models = TRUE)
r$models
#&gt; [[1]]
#&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph
#&gt; Trained on: task.id = lung-example; obs = 112; features = 8
#&gt; Hyperparameters:
#&gt;
#&gt; [[2]]
#&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph
#&gt; Trained on: task.id = lung-example; obs = 111; features = 8
#&gt; Hyperparameters:
#&gt;
#&gt; [[3]]
#&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph
#&gt; Trained on: task.id = lung-example; obs = 111; features = 8
#&gt; Hyperparameters:
</code></pre>

<h3 id="the-extract-option">The extract option</h3>
<p>Keeping complete fitted models can be memory-intensive if these objects are large or
the number of resampling iterations is high.
Alternatively, you can use the <code>extract</code> argument of <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> to retain only the
information you need.
To this end you need to pass a <a href="http://www.rdocumentation.org/packages/base/functions/function.html">function</a> to <code>extract</code> which is applied
to each <a href="http://www.rdocumentation.org/packages/mlr/functions/makeWrappedModel.html">WrappedModel</a> object fitted in each resampling iteration.</p>
<p>Below, we cluster the <a href="datasets::mtcars">mtcars</a> data using the <script type="math/tex">k</script>-means algorithm with <script type="math/tex">k = 3</script>
and keep only the cluster centers.</p>
<pre><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)

## Extract the compute cluster centers
r = resample(&quot;cluster.kmeans&quot;, mtcars.task, rdesc, show.info = FALSE,
  centers = 3, extract = function(x) getLearnerModel(x)$centers)
r$extract
#&gt; [[1]]
#&gt;        mpg      cyl     disp        hp     drat       wt     qsec
#&gt; 1 16.23333 7.666667 308.9667 214.00000 3.400000 3.564167 16.37000
#&gt; 2 26.00833 4.333333 113.5917  86.08333 4.040833 2.368583 18.88917
#&gt; 3 13.33333 8.000000 444.0000 198.33333 3.003333 4.839667 17.61667
#&gt;          vs        am     gear     carb
#&gt; 1 0.1666667 0.3333333 3.666667 3.666667
#&gt; 2 0.8333333 0.6666667 4.083333 1.916667
#&gt; 3 0.0000000 0.0000000 3.000000 3.333333
#&gt;
#&gt; [[2]]
#&gt;       mpg cyl     disp     hp  drat       wt     qsec    vs   am  gear
#&gt; 1 15.5600   8 326.0400 207.00 3.198 3.830000 16.74600 0.000 0.10 3.200
#&gt; 2 26.7125   4 102.8875  86.00 4.145 2.179125 19.05375 0.875 0.75 4.125
#&gt; 3 19.1500   6 174.4000 128.25 3.550 3.136250 17.91000 0.500 0.50 4.000
#&gt;    carb
#&gt; 1 3.500
#&gt; 2 1.625
#&gt; 3 3.750
#&gt;
#&gt; [[3]]
#&gt;        mpg cyl     disp       hp     drat       wt     qsec        vs
#&gt; 1 25.25000   4 113.6000  82.5000 3.932500 2.622500 19.17000 1.0000000
#&gt; 2 15.12000   8 369.8600 201.9000 3.211000 4.098900 17.05300 0.0000000
#&gt; 3 19.74286   6 183.3143 122.2857 3.585714 3.117143 17.97714 0.5714286
#&gt;          am     gear     carb
#&gt; 1 0.7500000 4.000000 1.500000
#&gt; 2 0.1000000 3.200000 3.200000
#&gt; 3 0.4285714 3.857143 3.428571
</code></pre>

<p>As a second example, we extract the variable importances from fitted regression trees using
function <a href="http://www.rdocumentation.org/packages/mlr/functions/getFeatureImportance.html">getFeatureImportance</a>.
(For more detailed information on this topic see the
<a href="../feature_selection/index.html">feature selection</a> page.)</p>
<pre><code class="r">## Extract the variable importance in a regression tree
r = resample(&quot;regr.rpart&quot;, bh.task, rdesc, show.info = FALSE, extract = getFeatureImportance)
r$extract
#&gt; [[1]]
#&gt; FeatureImportance:
#&gt; Task: BostonHousing-example
#&gt;
#&gt; Learner: regr.rpart
#&gt; Measure: NA
#&gt; Contrast: NA
#&gt; Aggregation: function (x)  x
#&gt; Replace: NA
#&gt; Number of Monte-Carlo iterations: NA
#&gt; Local: FALSE
#&gt;       crim       zn    indus     chas      nox       rm      age      dis
#&gt; 1 3842.839 952.3849 4443.578 90.63669 3772.273 15853.01 3997.275 3355.651
#&gt;        rad     tax  ptratio b    lstat
#&gt; 1 987.4256 568.177 2860.129 0 11255.66
#&gt;
#&gt; [[2]]
#&gt; FeatureImportance:
#&gt; Task: BostonHousing-example
#&gt;
#&gt; Learner: regr.rpart
#&gt; Measure: NA
#&gt; Contrast: NA
#&gt; Aggregation: function (x)  x
#&gt; Replace: NA
#&gt; Number of Monte-Carlo iterations: NA
#&gt; Local: FALSE
#&gt;       crim       zn    indus chas      nox       rm      age      dis
#&gt; 1 3246.521 3411.444 5806.613    0 2349.776 10125.04 5692.587 2108.059
#&gt;        rad     tax  ptratio        b    lstat
#&gt; 1 312.6521 2159.42 1104.839 174.6412 15871.53
#&gt;
#&gt; [[3]]
#&gt; FeatureImportance:
#&gt; Task: BostonHousing-example
#&gt;
#&gt; Learner: regr.rpart
#&gt; Measure: NA
#&gt; Contrast: NA
#&gt; Aggregation: function (x)  x
#&gt; Replace: NA
#&gt; Number of Monte-Carlo iterations: NA
#&gt; Local: FALSE
#&gt;       crim      zn    indus chas      nox       rm      age      dis
#&gt; 1 3785.852 1649.28 4942.119    0 3989.326 18426.87 2604.239 350.8401
#&gt;       rad      tax  ptratio        b    lstat
#&gt; 1 800.798 2907.556 3871.556 491.6297 12505.88
</code></pre>

<h2 id="stratification-and-blocking">Stratification and blocking</h2>
<ul>
<li><em>Stratification</em> with respect to a categorical variable makes sure that all its values
  are present in each training and test set in approximately the same proportion as in the original data set.
  Stratification is possible with regard to categorical target variables (and thus for supervised
  classification and survival analysis) or categorical explanatory variables.</li>
<li><em>Blocking</em> refers to the situation that subsets of observations belong together and must not
  be separated during resampling.
  Hence, for one train/test set pair the entire block is either in the training set or in
  the test set.</li>
</ul>
<h3 id="stratification-with-respect-to-the-target-variables">Stratification with respect to the target variable(s)</h3>
<p>For classification, it is usually desirable to have the same proportion of the classes in
all of the partitions of the original data set.
This is particularly useful in the case of imbalanced classes and small data sets. Otherwise,
it may happen that observations of less frequent classes are missing in some of the training
sets which can decrease the performance of the learner, or lead to model crashes.
In order to conduct stratified resampling, set <code>stratify = TRUE</code> in <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>.</p>
<pre><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, stratify = TRUE)

r = resample(&quot;classif.lda&quot;, iris.task, rdesc, show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: iris-example
#&gt; Learner: classif.lda
#&gt; Aggr perf: mmce.test.mean=0.0132
#&gt; Runtime: 0.064024
</code></pre>

<p>Stratification is also available for survival tasks.
Here the stratification balances the censoring rate.</p>
<h3 id="stratification-with-respect-to-explanatory-variables">Stratification with respect to explanatory variables</h3>
<p>Sometimes it is required to also stratify on the input data, e.g., to ensure that all
subgroups are represented in all training and test sets.
To stratify on the input columns, specify <a href="http://www.rdocumentation.org/packages/base/functions/factor.html">factor</a> columns of your task data
via <code>stratify.cols</code>.</p>
<pre><code class="r">rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, stratify.cols = &quot;chas&quot;)

r = resample(&quot;regr.rpart&quot;, bh.task, rdesc, show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: BostonHousing-example
#&gt; Learner: regr.rpart
#&gt; Aggr perf: mse.test.mean=21.2
#&gt; Runtime: 0.078635
</code></pre>

<h3 id="blocking">Blocking</h3>
<p>If some observations "belong together" and must not be separated when splitting the
data into training and test sets for resampling, you can supply this information via a
<code>blocking</code> <a href="base::factor">factor</a> when <a href="../task/index.html#further-settings">creating the task</a>.</p>
<pre><code class="r">## 5 blocks containing 30 observations each
task = makeClassifTask(data = iris, target = &quot;Species&quot;, blocking = factor(rep(1:5, each = 30)))
task
#&gt; Supervised task: iris
#&gt; Type: classif
#&gt; Target: Species
#&gt; Observations: 150
#&gt; Features:
#&gt; numerics  factors  ordered
#&gt;        4        0        0
#&gt; Missings: FALSE
#&gt; Has weights: FALSE
#&gt; Has blocking: TRUE
#&gt; Classes: 3
#&gt;     setosa versicolor  virginica
#&gt;         50         50         50
#&gt; Positive class: NA
</code></pre>

<h2 id="resample-descriptions-and-resample-instances">Resample descriptions and resample instances</h2>
<p>As already mentioned, you can specify a resampling strategy using function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>.</p>
<pre><code class="r">rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
rdesc
#&gt; Resample description: cross-validation with 3 iterations.
#&gt; Predict: test
#&gt; Stratification: FALSE

str(rdesc)
#&gt; List of 4
#&gt;  $ id      : chr &quot;cross-validation&quot;
#&gt;  $ iters   : int 3
#&gt;  $ predict : chr &quot;test&quot;
#&gt;  $ stratify: logi FALSE
#&gt;  - attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;

str(makeResampleDesc(&quot;Subsample&quot;, stratify.cols = &quot;chas&quot;))
#&gt; List of 6
#&gt;  $ split        : num 0.667
#&gt;  $ id           : chr &quot;subsampling&quot;
#&gt;  $ iters        : int 30
#&gt;  $ predict      : chr &quot;test&quot;
#&gt;  $ stratify     : logi FALSE
#&gt;  $ stratify.cols: chr &quot;chas&quot;
#&gt;  - attr(*, &quot;class&quot;)= chr [1:2] &quot;SubsampleDesc&quot; &quot;ResampleDesc&quot;
</code></pre>

<p>The result <code>rdesc</code> inherits from class <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a> (short for
resample description) and, in principle, contains all necessary information about the
resampling strategy including the number of iterations, the proportion of training and test
sets, stratification variables, etc.</p>
<p>Given either the size of the data set at hand or the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a>, function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">makeResampleInstance</a>
draws the training and test sets according to the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a>.</p>
<pre><code class="r">## Create a resample instance based an a task
rin = makeResampleInstance(rdesc, iris.task)
rin
#&gt; Resample instance for 150 cases.
#&gt; Resample description: cross-validation with 3 iterations.
#&gt; Predict: test
#&gt; Stratification: FALSE

str(rin)
#&gt; List of 5
#&gt;  $ desc      :List of 4
#&gt;   ..$ id      : chr &quot;cross-validation&quot;
#&gt;   ..$ iters   : int 3
#&gt;   ..$ predict : chr &quot;test&quot;
#&gt;   ..$ stratify: logi FALSE
#&gt;   ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;
#&gt;  $ size      : int 150
#&gt;  $ train.inds:List of 3
#&gt;   ..$ : int [1:100] 88 129 94 109 108 43 72 47 137 39 ...
#&gt;   ..$ : int [1:100] 129 94 138 83 112 54 29 36 72 137 ...
#&gt;   ..$ : int [1:100] 88 138 109 83 112 108 54 29 36 43 ...
#&gt;  $ test.inds :List of 3
#&gt;   ..$ : int [1:50] 2 5 6 13 14 17 20 21 24 25 ...
#&gt;   ..$ : int [1:50] 3 4 7 8 11 12 22 30 34 35 ...
#&gt;   ..$ : int [1:50] 1 9 10 15 16 18 19 23 27 28 ...
#&gt;  $ group     : Factor w/ 0 levels:
#&gt;  - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot;

## Create a resample instance given the size of the data set
rin = makeResampleInstance(rdesc, size = nrow(iris))
str(rin)
#&gt; List of 5
#&gt;  $ desc      :List of 4
#&gt;   ..$ id      : chr &quot;cross-validation&quot;
#&gt;   ..$ iters   : int 3
#&gt;   ..$ predict : chr &quot;test&quot;
#&gt;   ..$ stratify: logi FALSE
#&gt;   ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;
#&gt;  $ size      : int 150
#&gt;  $ train.inds:List of 3
#&gt;   ..$ : int [1:100] 149 58 120 44 148 29 66 46 124 137 ...
#&gt;   ..$ : int [1:100] 51 58 64 148 56 46 124 8 14 137 ...
#&gt;   ..$ : int [1:100] 149 51 120 44 64 56 29 66 8 14 ...
#&gt;  $ test.inds :List of 3
#&gt;   ..$ : int [1:50] 3 8 12 14 17 22 23 24 32 34 ...
#&gt;   ..$ : int [1:50] 1 2 4 6 10 11 13 26 29 30 ...
#&gt;   ..$ : int [1:50] 5 7 9 15 16 18 19 20 21 25 ...
#&gt;  $ group     : Factor w/ 0 levels:
#&gt;  - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot;

## Access the indices of the training observations in iteration 3
rin$train.inds[[3]]
#&gt;   [1] 149  51 120  44  64  56  29  66   8  14  83  65  97 114  13   3 104
#&gt;  [18]  88 130  81  89  23  63 131  92  31  41  78  72 139  67  10  57  12
#&gt;  [35] 107  74  70 116  36  24  35  93 126 111  75  91  80  85  42  30  22
#&gt;  [52]   1  69 113  87  26  17 150 119   4 138 129 147  38  99  60 142  50
#&gt;  [69] 122  40 127  43  96  34 141 106  79 133 145 125 135 108  52 109  37
#&gt;  [86]  61  84  59  39  82  32  53  94   6  45  86  95   2  68  11
</code></pre>

<p>The result <code>rin</code> inherits from class <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a> and contains
<a href="http://www.rdocumentation.org/packages/base/functions/list.html">list</a>s of index vectors for the train and test sets.</p>
<p>If a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a> is passed to <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>, it is instantiated internally.
Naturally, it is also possible to pass a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a> directly.</p>
<p>While the separation between resample descriptions, resample instances, and the <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>
function itself seems overly complicated, it has several advantages:</p>
<ul>
<li>Resample instances readily allow for paired experiments, that is comparing the performance
  of several learners on exactly the same training and test sets.
  This is particularly useful if you want to add another method to a comparison experiment
  you already did.
  Moreover, you can store the resample instance along with your data in order to be able to reproduce
  your results later on.</li>
</ul>
<pre><code class="r">rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
rin = makeResampleInstance(rdesc, task = iris.task)

## Calculate the performance of two learners based on the same resample instance
r.lda = resample(&quot;classif.lda&quot;, iris.task, rin, show.info = FALSE)
r.rpart = resample(&quot;classif.rpart&quot;, iris.task, rin, show.info = FALSE)
r.lda$aggr
#&gt; mmce.test.mean
#&gt;           0.02

r.rpart$aggr
#&gt; mmce.test.mean
#&gt;     0.05333333
</code></pre>

<ul>
<li>In order to add further resampling methods you can simply derive from the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a>
  and <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a> classes, but you do neither have to touch <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>
  nor any further methods that use the resampling strategy.</li>
</ul>
<p>Usually, when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">makeResampleInstance</a> the train and test index sets are drawn randomly.
Mainly for <em>holdout</em> (<em>test sample</em>) <em>estimation</em> you might want full control about the training
and tests set and specify them manually.
This can be done using function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeFixedHoldoutInstance.html">makeFixedHoldoutInstance</a>.</p>
<pre><code class="r">rin = makeFixedHoldoutInstance(train.inds = 1:100, test.inds = 101:150, size = 150)
rin
#&gt; Resample instance for 150 cases.
#&gt; Resample description: holdout with 0.67 split rate.
#&gt; Predict: test
#&gt; Stratification: FALSE
</code></pre>

<h2 id="aggregating-performance-values">Aggregating performance values</h2>
<p>In each resampling iteration <script type="math/tex">b = 1,\ldots,B</script> we get performance values
<script type="math/tex">S(D^{*b}, D \setminus D^{*b})</script> (for each measure we wish to calculate), which are then
aggregated to an overall performance.</p>
<p>For the great majority of common resampling strategies (like holdout, cross-validation, subsampling)
performance values are calculated on the test data sets only and for most measures aggregated
by taking the mean (<a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.mean</a>).</p>
<p>Each performance <a href="http://www.rdocumentation.org/packages/mlr/functions/makeMeasure.html">Measure</a> in <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> has a corresponding default aggregation
method which is stored in slot <code>$aggr</code>.
The default aggregation for most measures is <a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.mean</a>.
One exception is the root mean square error (<a href="../measures/index.html">rmse</a>).</p>
<pre><code class="r">## Mean misclassification error
mmce$aggr
#&gt; Aggregation function: test.mean

mmce$aggr$fun
#&gt; function (task, perf.test, perf.train, measure, group, pred)
#&gt; mean(perf.test)
#&gt; &lt;bytecode: 0x7fc2c23b0120&gt;
#&gt; &lt;environment: namespace:mlr&gt;

## Root mean square error
rmse$aggr
#&gt; Aggregation function: test.rmse

rmse$aggr$fun
#&gt; function (task, perf.test, perf.train, measure, group, pred)
#&gt; sqrt(mean(perf.test^2))
#&gt; &lt;bytecode: 0x7fc2c746b0d8&gt;
#&gt; &lt;environment: namespace:mlr&gt;
</code></pre>

<p>You can change the aggregation method of a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeMeasure.html">Measure</a> via function <a href="http://www.rdocumentation.org/packages/mlr/functions/setAggregation.html">setAggregation</a>.
All available aggregation schemes are listed on the <a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">aggregations</a> documentation page.</p>
<h3 id="example-one-measure-with-different-aggregations">Example: One measure with different aggregations</h3>
<p>The aggregation schemes <a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.median</a>, <a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.min</a>, and
<a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.max</a> compute the median, minimum, and maximum of the performance values
on the test sets.</p>
<pre><code class="r">mseTestMedian = setAggregation(mse, test.median)
mseTestMin = setAggregation(mse, test.min)
mseTestMax = setAggregation(mse, test.max)

mseTestMedian
#&gt; Name: Mean of squared errors
#&gt; Performance measure: mse
#&gt; Properties: regr,req.pred,req.truth
#&gt; Minimize: TRUE
#&gt; Best: 0; Worst: Inf
#&gt; Aggregated by: test.median
#&gt; Note: Defined as: mean((response - truth)^2)

rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
r = resample(&quot;regr.lm&quot;, bh.task, rdesc, measures = list(mse, mseTestMedian, mseTestMin, mseTestMax))
#&gt; [Resample] cross-validation iter 1:
#&gt; mse.test.mean=28.2,mse.test.median=28.2,mse.test.min=28.2,mse.test.max=28.2
#&gt; [Resample] cross-validation iter 2:
#&gt; mse.test.mean=17.6,mse.test.median=17.6,mse.test.min=17.6,mse.test.max=17.6
#&gt; [Resample] cross-validation iter 3:
#&gt; mse.test.mean=  25,mse.test.median=  25,mse.test.min=  25,mse.test.max=  25
#&gt; [Resample] Aggr. Result: mse.test.mean=23.6,mse.test.median=  25,mse.test.min=17.6,mse.test.max=28.2

r
#&gt; Resample Result
#&gt; Task: BostonHousing-example
#&gt; Learner: regr.lm
#&gt; Aggr perf: mse.test.mean=23.6,mse.test.median=  25,mse.test.min=17.6,mse.test.max=28.2
#&gt; Runtime: 0.0982959

r$aggr
#&gt;   mse.test.mean mse.test.median    mse.test.min    mse.test.max
#&gt;        23.57189        24.95722        17.59398        28.16447
</code></pre>

<h3 id="example-calculating-the-training-error">Example: Calculating the training error</h3>
<p>Below we calculate the mean misclassification error (<a href="../measures/index.html">mmce</a>) on the training
and the test data sets. Note that we have to set <code>predict = "both"</code> when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>
in order to get predictions on both training and test sets.</p>
<pre><code class="r">mmceTrainMean = setAggregation(mmce, train.mean)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, predict = &quot;both&quot;)
r = resample(&quot;classif.rpart&quot;, iris.task, rdesc, measures = list(mmce, mmceTrainMean))
#&gt; [Resample] cross-validation iter 1:
#&gt; mmce.train.mean=0.02,mmce.test.mean= 0.1
#&gt; [Resample] cross-validation iter 2:
#&gt; mmce.train.mean=0.04,mmce.test.mean=0.04
#&gt; [Resample] cross-validation iter 3:
#&gt; mmce.train.mean=0.04,mmce.test.mean=0.04
#&gt; [Resample] Aggr. Result: mmce.test.mean=0.06,mmce.train.mean=0.0333

r$measures.train
#&gt;   iter mmce mmce
#&gt; 1    1 0.02 0.02
#&gt; 2    2 0.04 0.04
#&gt; 3    3 0.04 0.04

r$aggr
#&gt;  mmce.test.mean mmce.train.mean
#&gt;      0.06000000      0.03333333
</code></pre>

<h3 id="example-bootstrap">Example: Bootstrap</h3>
<p>In <em>out-of-bag bootstrap estimation</em> <script type="math/tex">B</script> new data sets <script type="math/tex">D^{*1}, \ldots, D^{*B}</script> are drawn
from the data set <script type="math/tex">D</script> with replacement, each of the same size as <script type="math/tex">D</script>.
In the <script type="math/tex">b</script>-th iteration, <script type="math/tex">D^{*b}</script> forms the training set, while the remaining elements from
<script type="math/tex">D</script>, i.e., <script type="math/tex">D \setminus D^{*b}</script>, form the test set.</p>
<!--(
                     |resampling_desc_figure|

                     |resampling_nested_resampling_figure|
)-->

<p>The <em>b632</em> and <em>b632+</em> variants calculate a convex combination of the training performance and
the out-of-bag bootstrap performance and thus require predictions on the training sets and an
appropriate aggregation strategy.</p>
<pre><code class="r">## Use bootstrap as resampling strategy and predict on both train and test sets
rdesc = makeResampleDesc(&quot;Bootstrap&quot;, predict = &quot;both&quot;, iters = 10)

## Set aggregation schemes for b632 and b632+ bootstrap
mmceB632 = setAggregation(mmce, b632)
mmceB632plus = setAggregation(mmce, b632plus)

mmceB632
#&gt; Name: Mean misclassification error
#&gt; Performance measure: mmce
#&gt; Properties: classif,classif.multi,req.pred,req.truth
#&gt; Minimize: TRUE
#&gt; Best: 0; Worst: 1
#&gt; Aggregated by: b632
#&gt; Note: Defined as: mean(response != truth)

r = resample(&quot;classif.rpart&quot;, iris.task, rdesc, measures = list(mmce, mmceB632, mmceB632plus),
  show.info = FALSE)
head(r$measures.train)
#&gt;   iter       mmce       mmce       mmce
#&gt; 1    1 0.04000000 0.04000000 0.04000000
#&gt; 2    2 0.04000000 0.04000000 0.04000000
#&gt; 3    3 0.01333333 0.01333333 0.01333333
#&gt; 4    4 0.02666667 0.02666667 0.02666667
#&gt; 5    5 0.01333333 0.01333333 0.01333333
#&gt; 6    6 0.02000000 0.02000000 0.02000000

## Compare misclassification rates for out-of-bag, b632, and b632+ bootstrap
r$aggr
#&gt; mmce.test.mean      mmce.b632  mmce.b632plus
#&gt;     0.05804883     0.04797219     0.04860054
</code></pre>

<h2 id="convenience-functions">Convenience functions</h2>
<p>The functionality described on this page allows for much control and flexibility.
However, when quickly trying out some learners, it can get tedious to type all the
code for defining the resampling strategy, setting the aggregation scheme and so
on.
As mentioned above, <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> includes some pre-defined resample description objects for
frequently used strategies like, e.g., 5-fold cross-validation (<a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">cv5</a>).
Moreover, <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> provides special functions for the most common resampling methods,
for example <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">holdout</a>, <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">crossval</a>, or <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">bootstrapB632</a>.</p>
<pre><code class="r">crossval(&quot;classif.lda&quot;, iris.task, iters = 3, measures = list(mmce, ber))
#&gt; [Resample] cross-validation iter 1:
#&gt; mmce.test.mean=0.02,ber.test.mean=0.0159
#&gt; [Resample] cross-validation iter 2:
#&gt; mmce.test.mean=0.04,ber.test.mean=0.0415
#&gt; [Resample] cross-validation iter 3:
#&gt; mmce.test.mean=   0,ber.test.mean=   0
#&gt; [Resample] Aggr. Result: mmce.test.mean=0.02,ber.test.mean=0.0191
#&gt; Resample Result
#&gt; Task: iris-example
#&gt; Learner: classif.lda
#&gt; Aggr perf: mmce.test.mean=0.02,ber.test.mean=0.0191
#&gt; Runtime: 0.0689909

bootstrapB632plus(&quot;regr.lm&quot;, bh.task, iters = 3, measures = list(mse, mae))
#&gt; [Resample] OOB bootstrapping iter 1:
#&gt; mse.b632plus=18.9,mae.b632plus=3.09,mse.b632plus=29.3,mae.b632plus=3.77
#&gt; [Resample] OOB bootstrapping iter 2:
#&gt; mse.b632plus=17.9,mae.b632plus=3.03,mse.b632plus=26.4,mae.b632plus= 3.6
#&gt; [Resample] OOB bootstrapping iter 3:
#&gt; mse.b632plus=20.9,mae.b632plus=3.26,mse.b632plus=23.8,mae.b632plus=3.68
#&gt; [Resample] Aggr. Result: mse.b632plus=23.9,mae.b632plus=3.49
#&gt; Resample Result
#&gt; Task: BostonHousing-example
#&gt; Learner: regr.lm
#&gt; Aggr perf: mse.b632plus=23.9,mae.b632plus=3.49
#&gt; Runtime: 0.100332
</code></pre></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
        <script src="../js/base.js"></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
