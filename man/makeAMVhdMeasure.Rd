% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Make_measure_AMVhd.R
\name{makeAMVhdMeasure}
\alias{makeAMVhdMeasure}
\title{Creates the measure Area under Mass-Volume Curve (AMV) for Anomaly detection (oneclass) for high dimensional data}
\usage{
makeAMVhdMeasure(id = "AMVhd", minimize = TRUE, amv.iters = 10,
  amv.feats = 3, alphas = c(0.9, 0.99), n.alpha = 50, n.sim = 1e+05,
  best = 0, worst = NULL, name = id, note = "")
}
\arguments{
\item{id}{[\code{character(1)}]\cr
Name of measure.}

\item{minimize}{[\code{logical(1)}]\cr
Should the measure be minimized?
Default is \code{TRUE}.}

\item{alphas}{[\code{numeric}] \cr
Numeric vector of alphas, which lies in [0, 1), representing the computed quantiles.
Default: lower quantile alpha1 = 0.9, upper quantile alpha2 = 0.99 as we are interested in the performance of the scoring function in the the low density regions.}

\item{n.alpha}{[\code{numeric}] \cr
Numeric discretization parameter greater than one, which splits the intervall of alpha1 and alpha2 as follows: {alpha1 + j * (alpha2-alpha1)/(n.alpha-1), j element of {0,...,n.alpha-1}}, Default: n.alpha = 50.}

\item{n.sim}{[\code{numeric(1)}] \cr
Number of Monte-Carlo Samples, Default: 10^4.}

\item{best}{[\code{numeric(1)}]\cr
Best obtainable value for measure.
Default is -\code{Inf} or \code{Inf}, depending on \code{minimize}.}

\item{worst}{[\code{numeric(1)}]\cr
Worst obtainable value for measure.
Default is \code{Inf} or -\code{Inf}, depending on \code{minimize}.}

\item{name}{[\code{character}] \cr
Name of the measure. Default is \code{id}.}

\item{note}{[\code{character}] \cr
Description and additional notes for the measure. Default is \dQuote{}.}
}
\value{
[\code{numeric(1)}]
  Area under Mass-Volume Curve (AMV) for high dimensional data.

[\code{\link{Measure}}].
}
\description{
Creates a measure for oneclass classification on high dimensional data
(recommend for dimension greater than 8) called AMVhd, which is based on the
Area under the Mass-Volume Curve (AMV) (see \code{makeAMVMeasure}).
The basic idea is to do several feature sub-samplings (of dimension less than 8)
to reduce the dimension of the data, therefore AMV can be applied on each
subsamples, yielding partial scores AMV_k. The mean of the partial scores is
the new performancecriteria AMVhd.
}
\examples{
# creates anomaly data with feature size nine
sigma = matrix(0, 9, 9)
diag(sigma) = c(4, 5, 8, 3, 2, 6, 9, 3, 1)
normal = mvrnorm(n = 1000, rep(0, 9), sigma)
colnames(normal) = paste0("V", 1:9)
normal = as.data.frame(normal)
normal$normal = TRUE

anomaly = matrix(sample(size = 50 * 9, x = 20:100, replace = TRUE), 50, 9)
colnames(anomaly) = paste0("V", 1:9)
anomaly = as.data.frame(anomaly)
anomaly$normal = FALSE
data = rbind(normal, anomaly)
data = na.omit(data)

# create train and test sets
library(BBmisc)
inds.split = chunk(seq_len(nrow(data)), shuffle = TRUE, props = c(0.6, 0.4))
train.inds = inds.split[[1]]
test.inds = inds.split[[2]]

# creates an AMVhd measure which calculates the area under the curve between 0.8 and 0.99
# with 50 steps for high dimensional data.
AMVhd = makeAMVhdMeasure(id = "AMV", minimize = TRUE, alphas = c(0.8, 0.99),
n.alpha = 50, n.sim = 10e4, best = 0, worst = NULL)

task = makeOneClassTask(data = data, target = "normal", positive = "TRUE", negative = "FALSE")
# base learner
lrn = makeLearner("oneclass.svm", predict.type = "prob")

# for applying AMVhd we need to use the AMVhdWrapper
# wrapped learner, with 3 feature subsample for each of the 10 iteration
lrn_amww = makeAMVhdWrapper(lrn, amv.iters = 10, amv.feats = 3)
# wrapped model
mod_amww = train(lrn_amww, task, subset = train.inds)
# list all submodels, first list element is the full model
submod = getLearnerModel(mod_amww, more.unwrap = FALSE)
# wrapped prediction
pred_amww = predict(mod_amww, task, subset = test.inds)
# t contains the prediction with subsampled features
t = attr(pred_amww, "AMVhdSubpredict")

# calculate AMVhd performance
set.seed(123)
performance(pred = pred_amww, measures = list(AMVhd), model = mod_amww,
task = task, feats = data[test.inds, 1:9])
}
\references{
Nicolas, G. How to Evaluate the Quality of Unsupervised Anomaly Detection Algorithms,
arXiv preprint arXiv:1607.01152
}
\seealso{
Other performance.: \code{\link{makeAMVMeasure}}
}
