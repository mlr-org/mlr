% Generated by roxygen2 (4.0.1): do not edit by hand
\name{makeFeatSelControlExhaustive}
\alias{FeatSelControl}
\alias{FeatSelControlExhaustive}
\alias{FeatSelControlGA}
\alias{FeatSelControlRandom}
\alias{FeatSelControlSequential}
\alias{makeFeatSelControlExhaustive}
\alias{makeFeatSelControlGA}
\alias{makeFeatSelControlRandom}
\alias{makeFeatSelControlSequential}
\title{Create control structures for feature selection.}
\usage{
makeFeatSelControlExhaustive(same.resampling.instance = TRUE,
  maxit = NA_integer_, max.features = NA_integer_)

makeFeatSelControlGA(same.resampling.instance = TRUE, maxit = NA_integer_,
  max.features = NA_integer_, comma = FALSE, mu = 10L, lambda,
  crossover.rate = 0.5, mutation.rate = 0.05)

makeFeatSelControlRandom(same.resampling.instance = TRUE, maxit = 100L,
  max.features = NA_integer_, prob = 0.5)

makeFeatSelControlSequential(same.resampling.instance = TRUE, method,
  alpha = 0.01, beta = 0.01, maxit = NA_integer_,
  max.features = NA_integer_)
}
\arguments{
\item{same.resampling.instance}{[\code{logical(1)}]\cr
Should the same resampling instance be used for all evaluations to reduce variance?
Default is \code{TRUE}.}

\item{maxit}{[\code{integer(1)}]\cr
Maximal number of iterations. Note, that this is usually not equal to the number
of function evaluations.}

\item{max.features}{[\code{integer(1)}]\cr
Maximal number of features.}

\item{crossover.rate}{[\code{numeric(1)}]\cr
Parameter of the GA feature selection. Probability of choosing a bit from the first parent
within the crossover mutation.}

\item{mutation.rate}{[\code{numeric(1)}]\cr
Parameter of the GA feature selection. Probability of flipping a feature bit, i.e. switch
between selecting / deselecting a feature.}

\item{comma}{[\code{logical(1)}]\cr
Parameter of the GA feature selection, indicating whether to use a (\code{mu}, \code{lambda})
or (\code{mu} + \code{lambda}) GA. The default is \code{FALSE}.}

\item{mu}{[\code{integer(1)}]\cr
Parameter of the GA feature selection. Size of the parent population.}

\item{lambda}{[\code{integer(1)}]\cr
Parameter of the GA feature selection. Size of the children population (should be smaller
or equal to \code{mu}).}

\item{prob}{[\code{numeric(1)}]\cr
Parameter of the random feature selection. Probability of choosing a feature.}

\item{method}{[\code{character(1)}]\cr
Parameter of the sequential feature selection. A character representing the method. Possible
values are \code{sfs} (forward search), \code{sbs} (backward search), \code{sffs}
(floating forward search) and \code{sfbs} (floating backward search).}

\item{alpha}{[\code{numeric(1)}]\cr
Parameter of the sequential feature selection. Minimal value of improvement.}

\item{beta}{[\code{numeric(1)}]\cr
Parameter of the sequential feature selection. Maximal value of setback.}
}
\value{
[\code{\link{FeatSelControl}}]. The specific subclass is one of
  \code{\link{FeatSelControlExhaustive}}, \code{\link{FeatSelControlRandom}},
  \code{\link{FeatSelControlSequential}}, \code{\link{FeatSelControlGA}}.
}
\description{
Feature selection method used by \code{\link{selectFeatures}}.
The following methods are available:

 \describe{
   \item{FeatSelControlExhaustive}{Exhaustive search. All feature sets (up to a certain number
     of features \code{max.features}) are searched.}
   \item{FeatSelControlRandom}{Random search. Features vectores are randomly drawn,
     up to a certain number of features \code{max.features}.
     A feature is included in the current set with probability \code{prob}.
     So we are basically drawing (0,1)-membership-vectors, where each element
     is Bernoulli(\code{prob}) distributed.}
   \item{FeatSelControlSequential}{Deterministic forward or backward search. That means extending
     (forward) or shrinking (backward) an existing model stepwise by calculating the performance
     of the existing model with variables added (forward) or removed (backward).
     Depending on the given \code{method} different approches are taken.\cr
     \code{sfs} Sequential Forward Search: Starting from an empty model, in each step the feature increasing
     the performance measure the most is added to the model.\cr
     \code{sbs} Sequential Backward Search: Starting from a model with all features, in each step the feature
     decreasing the performance measure the least is removed from the model.\cr
     \code{sffs} Sequential Floating Forward Search: Starting from an empty model, in each step the algorithm
     chooses the best model from all models with one additional feature and from all models with one
     feature less.\cr
     \code{sfbs} Sequential Floating Backward Search: Similar to \code{sffs} but starting with a full model.}
   \item{FeatSelControlGA}{Search via genetic algorithm.
     The GA is a simple (\code{mu}, \code{lambda}) or (\code{mu} + \code{lambda}) algorithm,
     depending on the \code{comma} setting.
     A comma strategy selects a new population of size \code{mu} out of the
     \code{lambda} > \code{mu} offspring.
     A plus strategy uses the joint pool of \code{mu} parents and \code{lambda} offspring
     for selecting \code{mu} new candidates.
     Out of those \code{mu} features, the new \code{lambda} features are generated
     by randomly choosing pairs of parents. These are crossed over and \code{crossover.rate}
     represents the probability of choosing a feature from the first parent instead of
     the second parent.
     The resulting offspring is mutated, i.e., its bits are flipped with
     probability \code{mutation.rate}. If \code{max.features} is set, offspring are
     repeatedly generated until the setting is satisfied.}
 }
}
\seealso{
\code{\link{selectFeatures}}, \code{\link{analyzeFeatSelResult}}
}

